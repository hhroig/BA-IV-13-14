library(ISLR)
df <- Default[, c("income", "balance", "default")]
set.seed(123)
train.ID <- createDataPartition(df$default, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# definimos como control una validación cruzada con 10 hojas y repeticiones
fit_control <- trainControl(method='repeatedcv', number = 10, repeats = 5)
# LDA
set.seed(321)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control)
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control)
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control)
set.seed(321)
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5)
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, metric = "Accuracy")
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
# hagamos las predicciones del conjunto de prueba
pred_prob <- predict(model_lda_def, newdata = test_df, type = "prob")
library(ROCR)
library(dplyr)
prob.pred <- prediction(pred_prob[,2], test_df$default)
# ROC
prob.pred %>%
performance(measure = "tpr", x.measure = "fpr") %>%
plot()
# AUC: mientras mas cercano a 1, mejor predicciones
auc.lda <- performance(prob.pred, measure = "auc")@y.values[[1]]
auc.lda
prob.pred %>%
performance("err") %>%
plot()
prob.pred %>%
performance("tpr") %>%
plot()
prob.pred %>%
performance("fpr") %>%
plot()
prob.pred %>%
performance("fnr") %>%
plot()
# Podemos combinar las 3 ultimas en un mismo grafico
df_perfor <- data.frame(Error.Rate = performance(prob.pred, "err")@y.values[[1]],
FNR = performance(prob.pred, "fnr")@y.values[[1]],
FPR = performance(prob.pred, "fpr")@y.values[[1]],
TPR = performance(prob.pred, "tpr")@y.values[[1]],
CutOffs = performance(prob.pred, "err")@x.values[[1]])
# plot tasas de error
errores.lda <- ggplot(df_perfor, aes(x = CutOffs)) +
geom_line(aes(y = Error.Rate, colour = "Tasa Error General")) +
geom_line(aes(y = FNR, colour = "FNR")) +
geom_line(aes(y = FPR, colour = "FPR")) +
scale_colour_discrete(name = "Medidas" ) +
xlab("Puntos de corte") + ylab("Tasas de Error") +
theme_light()
errores.lda
# plot de la curva ROC
roc.lda <- ggplot(df_perfor, aes(x = FPR, y = TPR)) +
geom_line() +
xlab("FPR: 1- especificidad") + ylab("TPR: sensibilidad") +
ggtitle(paste0("Curva ROC - LDA (Area Under Curve = ", round(auc.lda, digits = 3),")")) +
theme_light()
roc.lda
# definimos como control una validación cruzada con 10 hojas y repeticiones
fit_control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
## Estimar las probabilidades:
classProbs = TRUE,
## Evaluar rendimiento del modelo:
summaryFunction = twoClassSummary)
# LDA
set.seed(321)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
set.seed(321)
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5,
## Especificamos la métrica para optimizar:
metric = "ROC")
model_knn_def
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, metric = "ROC")
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
decision_bound = function(train_df_in, test_df_in, model_in){
# plot decision boundary  for df <- Default[, c("income", "balance", "default")]
require(MASS)
require(caret)
require(ggplot2)
require(gridExtra)
# Paso 1: crear un grid de valores desde min a max de ambos predictores
pl = seq(min(train_df_in$balance), max(train_df_in$balance), length.out = 80)
pw = seq(min(train_df_in$income), max(train_df_in$income), length.out = 80)
lgrid <- expand.grid(balance=pl, income=pw)
# Paso 2: obtener las predicciones tanto para el grid como para el test
modelPredGrid <- predict(model_in, newdata=lgrid)
train_df_in$Pred.Class <- predict(model_in, newdata = train_df_in)
test_df_in$Pred.Class <- predict(model_in, newdata = test_df_in)
# Paso 3: ggplot con la funcion contour
gg1 <- ggplot(data=lgrid) +
stat_contour(aes(x=balance, y=income, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=balance, y=income, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Train") +
geom_point(data=train_df_in,
aes(x=balance, y=income,
colour=default), size=5, shape=1) +
theme_light()
gg2 <- ggplot(data=lgrid) +
stat_contour(aes(x=balance, y=income, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=balance, y=income, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Test") +
geom_point(data=test_df_in,
aes(x=balance, y=income,
colour=default), size=5, shape=1) +
theme_light()
grid.arrange(gg1, gg2, ncol=1, nrow=2)
}
decision_bound(train_df, test_df, model_lda_def)
# hagamos las predicciones del conjunto de prueba
prediction_qda_def <- predict(model_qda_def, newdata = test_df)
confusionMatrix(prediction_qda_def, reference = test_df$default)
df <- Default[, c("income", "balance", "default")]
set.seed(123)
train.ID <- createDataPartition(df$default, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# definimos como control una validación cruzada con 10 hojas, sin repeticiones
fit_control <- trainControl(method='cv', number = 10)
set.seed(123)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control)
model_lda_def
model_lda_def$finalModel
# hagamos las predicciones del conjunto de prueba
prediction_lda_def <- predict(model_lda_def, newdata = test_df)
confusionMatrix(prediction_lda_def, reference = test_df$default)
# extraemos el Accuracy o Precisión
confusionMatrix(prediction_lda_def, reference = test_df$default)$overall[1]
# la tasa de error
tasa.error.lda <- 1-confusionMatrix(prediction_lda_def, reference = test_df$default)$overall[1]
names(tasa.error.lda) <- "Error LDA"
tasa.error.lda
# hagamos las predicciones del conjunto de prueba
prediction_qda_def <- predict(model_qda_def, newdata = test_df)
confusionMatrix(prediction_qda_def,
reference = test_df$default,
positive = "Yes",
mode = "everything")
library(MASS)
df <- iris
set.seed(123)
train.ID <- createDataPartition(df$Species, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
lda_iris <- MASS::lda(Species ~ ., train_df)
lda_iris
View(lda_iris)
plot(lda.iris, col = as.integer(train$Species))
plot(lda.iris, col = as.integer(train_df$Species))
plot(lda_iris, col = as.integer(train_df$Species))
plot(lda.iris, dimen = 1, type = "b")
plot(lda_iris, dimen = 1, type = "b")
install.packages("infotheo")
library(infotheo)
knitr::kable(
head(iris, 10), caption = 'Estructura del dataset Iris',
booktabs = TRUE
)
# ya conocemos esta:
library(tidyverse)
# para usar knn:
library(class)
# esta es nueva para nosotros:
library(GGally)
df <- data(iris) # cargar datos
summary(iris) # un breve descriptivo
# ver el balance de la muestra, según las clases
prop.table(table(iris$Species))
# visualización
p1 <- ggpairs(iris,
aes(colour = Species, alpha = 0.2),
columns = c("Sepal.Length",  "Sepal.Width",
"Petal.Length", "Petal.Width")) +
theme_bw()
p1
p2 <- ggpairs(iris,
aes(colour = Species, alpha = 0.2),
lower=list(combo=wrap("facethist",
bins=round(sqrt(50))))) +
theme_bw() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
p2
iris.scl <- scale(iris[,1:4])
# set de índices para entrenar-validar (80% - 20%)
set.seed(123)
train.ID <- sample(1:nrow(iris), 0.8 * nrow(iris))
# matriz de diseño para entrenar
X.train <- iris.scl[train.ID,1:4]
# matriz de diseño para testear
X.test <- iris.scl[-train.ID,1:4]
# respuesta (categórica) entrenamiento
Y <- iris[train.ID,5]
# respuesta (categórica) test
Y.test <- iris[-train.ID,5]
# KNN
pr <- knn(X.train, X.test, cl=Y, k = round(sqrt(nrow(X.train))))
# matriz de confusión
tab <- table(pr,Y.test)
knitr::kable(
tab, caption = 'Matriz de Confusión - KNN Iris',
booktabs = TRUE)
# tasa de error test
test.error <- sum(pr != Y.test)/sum(tab)
test.error
test.error <- data.frame()
for (K in seq(1, 120, by = 5)) {
# KNN
pr <- knn(X.train,X.test,cl=Y,k=K)
# matriz de confusion
tab <- table(pr,Y.test)
# tasa de error test
test.error <- rbind(test.error,
data.frame(Tasa.Error = sum(pr != Y.test)/sum(tab), K))
}
ggplot(test.error, aes(x = K, y = Tasa.Error)) +
geom_point() +
geom_line() +
ylab("Tasa de Error (test)") +  xlab("K: número de vecinos") +
theme_light()
library(caret)
str(iris)
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "pairs",
## Add a key at the top
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(4,1 ),
auto.key = list(columns = 2))
# creamos una partición test
df <- iris
set.seed(123)
train.ID <- createDataPartition(df$Species, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# primeros pasos con la validación cruzada...
fit_control <- trainControl(method='cv', number = 10)
model_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 10)
model_knn_iris
plot(model_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris <- predict(model_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris, reference = test_df$Species)
# definimos el grid:
some_k <- expand.grid(k = 1:15)
# k-fold CV pero con repeticiones
fit_control1 <- trainControl(
method = "repeatedcv",
number = 10, # número de folds
repeats = 5 ) # repeticiones
# bootstrap
fit_control2 <- trainControl(
method = "boot",
number = 10) # número de muestras bootstrap
# LOOCV
fit_control3 <- trainControl(
method = "LOOCV")
model2_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control2,
preProcess = c("center", "scale"),
tuneGrid = some_k)
model2_knn_iris
plot(model2_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris2 <- predict(model2_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris2, reference = test_df$Species)
varImp(model_knn_iris)
mutinformation(train_df)
library(infotheo)
# mutual information computation
# ?mutinformation
mutinformation(X = train_df)
View(train_df)
glimpse(train_df)
?mutinformation
mutinformation(X = train_df[1, 4])
mutinformation(X = train_df[1:4])
train_df[1:4])
mutinformation(X = train_df[,1:4])
train_df[ ,1:4]
multinformation(X = train_df[ ,1:4])
multiinformation(X = train_df[ ,1:4])
multiinformation(train_df[ ,1:4])
data(USArrests)
dat<-discretize(USArrests)
M <- multiinformation(dat)
M <- multiinformation(dat)
M
View(dat)
data(USArrests)
data(USArrests)
dat<-discretize(USArrests)
#computes the MIM (mutual information matrix)
I <- mutinformation(dat,method= "emp")
I
I2<- mutinformation(dat[,1],dat[,2])
I2
?discretize
dat <- discretize(train_df)
# MI matrix:
MI <- mutinformation(dat, method= "emp")
MI
library(infotheo)
# ?mutinformation
dat <- discretize(train_df)
# MI matrix:
MI <- mutinformation(dat)
MI
library(infotheo)
# ?mutinformation
dat <- discretize(train_df)
# MI matrix:
MI <- mutinformation(dat, method= "emp")
MI
library(infotheo)
# ?mutinformation
dat <- discretize(train_df)
# MI matrix:
MI <- mutinformation(dat, method= "emp")
MI
View(dat)
View(MI)
MI %>%
dplyr::select(Species) %>%
ggplot(aes(x = Species)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble() %>%
dplyr::select(Species) %>%
ggplot(aes(x = Species)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble() %>%
dplyr::select(Species) %>%
ggplot(aes(y = Species)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble(
)
MI %>%
as_tibble() %>%
dplyr::select(Species)
MI %>%
as_tibble()
MI %>%
as_tibble() %>%
dplyr::select(Species)
dplyr::select(Variable, MI) %>%
ggplot(aes(x = Variable, y = MI)) +
geom_col(alpha= 0.5) +
theme_bw()
Variable = colnames(MI)
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = Variable, y = MI)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, MI), y = MI)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, -MI), y = MI)) +
geom_col(alpha= 0.5) +
theme_bw()
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, -MI), y = MI)) +
geom_col(alpha= 0.5) +
xlab("Variable") +
theme_bw()
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, -MI), y = MI)) +
geom_col(alpha= 0.5) +
xlab("Variable") +
theme(title = "MI: todas vs. Species")
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, -MI), y = MI)) +
geom_col(alpha= 0.5) +
labs(title = "MI: todas vs. Species", xlab = "Variable") +
theme_bw()
MI %>%
as_tibble() %>%
mutate(Variable = colnames(MI), MI = Species) %>%
dplyr::select(Variable, MI) %>%
ggplot(aes(x = reorder(Variable, -MI), y = MI)) +
geom_col(alpha= 0.5) +
labs(title = "MI: todas vs. Species", x = "Variable") +
theme_bw()
