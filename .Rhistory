prediction_lda_def <- predict(model_lda_def, newdata = test_df)
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control)
# hagamos las predicciones del conjunto de prueba
prediction_qda_def <- predict(model_qda_def, newdata = test_df)
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control)
# hagamos las predicciones del conjunto de prueba
prediction_rda_def <- predict(model_qda_def, newdata = test_df)
set.seed(321)
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5)
# hagamos las predicciones del conjunto de prueba
prediction_knn_def <- predict(model_knn_def, newdata = test_df)
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, layout = c(2, 1))
# box plots
bwplot(resamps, layout = c(1,2))
View(resamps)
# box plots
bwplot(resamps, metric = "Accuracy")
difValues <- diff(resamps)
difValues
# box plots
bwplot(difValues, metric = "Accuracy")
# intervalos de confianza para las diferencias
dotplot(difValues)
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
library(ROCR)
library(dplyr)
prob.pred <- prediction(pred_prob[,2], test_df$default)
library(caret)
library(ISLR)
df <- Default[, c("income", "balance", "default")]
set.seed(123)
train.ID <- createDataPartition(df$default, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# definimos como control una validación cruzada con 10 hojas y repeticiones
fit_control <- trainControl(method='repeatedcv', number = 10, repeats = 5)
# LDA
set.seed(321)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control)
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control)
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control)
set.seed(321)
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5)
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, metric = "Accuracy")
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
# hagamos las predicciones del conjunto de prueba
pred_prob <- predict(model_lda_def, newdata = test_df, type = "prob")
library(ROCR)
library(dplyr)
prob.pred <- prediction(pred_prob[,2], test_df$default)
# ROC
prob.pred %>%
performance(measure = "tpr", x.measure = "fpr") %>%
plot()
# AUC: mientras mas cercano a 1, mejor predicciones
auc.lda <- performance(prob.pred, measure = "auc")@y.values[[1]]
library(ROCR)
library(dplyr)
prob.pred <- prediction(pred_prob[,2], test_df$default)
# ROC
prob.pred %>%
performance(measure = "tpr", x.measure = "fpr") %>%
plot()
# AUC: mientras mas cercano a 1, mejor predicciones
auc.lda <- performance(prob.pred, measure = "auc")@y.values[[1]]
auc.lda
prob.pred %>%
performance("err") %>%
plot()
prob.pred %>%
performance("tpr") %>%
plot()
prob.pred %>%
performance("fpr") %>%
plot()
prob.pred %>%
performance("fnr") %>%
plot()
# Podemos combinar las 3 ultimas en un mismo grafico
df_perfor <- data.frame(Error.Rate = performance(prob.pred, "err")@y.values[[1]],
FNR = performance(prob.pred, "fnr")@y.values[[1]],
FPR = performance(prob.pred, "fpr")@y.values[[1]],
CutOffs = performance(prob.pred, "err")@x.values[[1]])
# plot tasas de error
errores.lda <- ggplot(df_perfor, aes(x = CutOffs)) +
geom_line(aes(y = Error.Rate, colour = "Tasa Error General")) +
geom_line(aes(y = FNR, colour = "FNR")) +
geom_line(aes(y = FPR, colour = "FPR")) +
scale_colour_discrete(name = "Medidas" ) +
xlab("Puntos de corte") + ylab("Tasas de Error") +
theme_light()
errores.lda
# plot de la curva ROC
roc.lda <- ggplot(df_perfor, aes(x = FPR, y = TPR)) +
geom_line() +
xlab("FPR: 1- especificidad") + ylab("TPR: sensibilidad") +
ggtitle(paste0("Curva ROC - LDA (Area Under Curve = ", round(auc.lda, digits = 3),")")) +
theme_light()
roc.lda
# Podemos combinar las 3 ultimas en un mismo grafico
df_perfor <- data.frame(Error.Rate = performance(prob.pred, "err")@y.values[[1]],
FNR = performance(prob.pred, "fnr")@y.values[[1]],
FPR = performance(prob.pred, "fpr")@y.values[[1]],
TPR = performance(prob.pred, "tpr")@y.values[[1]],
CutOffs = performance(prob.pred, "err")@x.values[[1]])
# plot tasas de error
errores.lda <- ggplot(df_perfor, aes(x = CutOffs)) +
geom_line(aes(y = Error.Rate, colour = "Tasa Error General")) +
geom_line(aes(y = FNR, colour = "FNR")) +
geom_line(aes(y = FPR, colour = "FPR")) +
scale_colour_discrete(name = "Medidas" ) +
xlab("Puntos de corte") + ylab("Tasas de Error") +
theme_light()
errores.lda
# plot de la curva ROC
roc.lda <- ggplot(df_perfor, aes(x = FPR, y = TPR)) +
geom_line() +
xlab("FPR: 1- especificidad") + ylab("TPR: sensibilidad") +
ggtitle(paste0("Curva ROC - LDA (Area Under Curve = ", round(auc.lda, digits = 3),")")) +
theme_light()
roc.lda
setwd("~/OneDrive - Universidad Carlos III de Madrid/Big_Analytics_Ed4/14_15_Aprendizaje_Supervisado_Harold_A_Hdez_Roig/codes_practica")
setwd("~/OneDrive - Universidad Carlos III de Madrid/Big_Analytics_Ed4/14_15_Aprendizaje_Supervisado_Harold_A_Hdez_Roig/codes_practica")
setwd("~/OneDrive - Universidad Carlos III de Madrid/Big_Analytics_Ed4/probar_wine_concurso")
train_df <- read_csv("train_data.csv", col_names = T)
library(readr)
train_df <- read_csv("train_data.csv", col_names = T)
head(train_df)
head(train_df)
train_df <- read_csv("train_data.csv", col_names = T)
test_df <- read_csv("test_data.csv", col_names = T)
head(train_df)
View(test_df)
library(caret)
# creamos la particion correspondiente para entrenar
df2 <- df
train.ID <- createDataPartition(df2$Origin, p = 0.7, list = FALSE)
fit_control <- trainControl(## 10-fold CV
method = "cv",
number = 5)
model_knn <- train(Origin ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 2)
model_knn
View(train_df)
train_df$Origin <-as.factor(train_df$Origin)
fit_control <- trainControl(## 10-fold CV
method = "cv",
number = 5)
model_knn <- train(Origin ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 2)
model_knn
plot(model_knn)
pred <- predict(model_knn, newdata = test_df)
my_submission <- data.frame(pred = pred)
write.csv(my_submission, file = "pruebita1.csv", row.names = FALSE)
fit_control <- trainControl(## 10-fold CV
method = "cv",
number = 10,
repeats = 5)
fit_control <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
repeats = 5)
model_knn <- train(Origin ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 30)
model_knn
pred <- predict(model_knn, newdata = test_df)
my_submission <- data.frame(pred = pred)
write.csv(my_submission, file = "pruebita1.csv", row.names = FALSE)
library(caret)
library(ISLR)
df <- Default[, c("income", "balance", "default")]
set.seed(123)
train.ID <- createDataPartition(df$default, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# definimos como control una validación cruzada con 10 hojas y repeticiones
fit_control <- trainControl(method='repeatedcv', number = 10, repeats = 5)
# LDA
set.seed(321)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control)
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control)
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control)
set.seed(321)
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5)
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, metric = "Accuracy")
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
# hagamos las predicciones del conjunto de prueba
pred_prob <- predict(model_lda_def, newdata = test_df, type = "prob")
library(ROCR)
library(dplyr)
prob.pred <- prediction(pred_prob[,2], test_df$default)
# ROC
prob.pred %>%
performance(measure = "tpr", x.measure = "fpr") %>%
plot()
# AUC: mientras mas cercano a 1, mejor predicciones
auc.lda <- performance(prob.pred, measure = "auc")@y.values[[1]]
auc.lda
prob.pred %>%
performance("err") %>%
plot()
prob.pred %>%
performance("tpr") %>%
plot()
prob.pred %>%
performance("fpr") %>%
plot()
prob.pred %>%
performance("fnr") %>%
plot()
# Podemos combinar las 3 ultimas en un mismo grafico
df_perfor <- data.frame(Error.Rate = performance(prob.pred, "err")@y.values[[1]],
FNR = performance(prob.pred, "fnr")@y.values[[1]],
FPR = performance(prob.pred, "fpr")@y.values[[1]],
TPR = performance(prob.pred, "tpr")@y.values[[1]],
CutOffs = performance(prob.pred, "err")@x.values[[1]])
# plot tasas de error
errores.lda <- ggplot(df_perfor, aes(x = CutOffs)) +
geom_line(aes(y = Error.Rate, colour = "Tasa Error General")) +
geom_line(aes(y = FNR, colour = "FNR")) +
geom_line(aes(y = FPR, colour = "FPR")) +
scale_colour_discrete(name = "Medidas" ) +
xlab("Puntos de corte") + ylab("Tasas de Error") +
theme_light()
errores.lda
# plot de la curva ROC
roc.lda <- ggplot(df_perfor, aes(x = FPR, y = TPR)) +
geom_line() +
xlab("FPR: 1- especificidad") + ylab("TPR: sensibilidad") +
ggtitle(paste0("Curva ROC - LDA (Area Under Curve = ", round(auc.lda, digits = 3),")")) +
theme_light()
roc.lda
# definimos como control una validación cruzada con 10 hojas y repeticiones
fit_control <- trainControl(method = "repeatedcv",
number = 10,
repeats = 5,
## Estimar las probabilidades:
classProbs = TRUE,
## Evaluar rendimiento del modelo:
summaryFunction = twoClassSummary)
# LDA
set.seed(321)
model_lda_def <- train(default ~.,
data = train_df,
method = "lda",
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
# QDA
set.seed(321)
model_qda_def <- train(default ~.,
data = train_df,
method = "qda",
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
# RDA
mi.grid <- data.frame(lambda = c(0) ,
gamma = c(0))
set.seed(321)
model_rda_def <- train(default ~.,
data = train_df,
method = "rda",
tuneGrid = mi.grid,
trControl = fit_control,
## Especificamos la métrica para optimizar:
metric = "ROC")
model_knn_def <- train(default ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 5,
## Especificamos la métrica para optimizar:
metric = "ROC")
resamps <- resamples(list(LDA = model_lda_def,
QDA = model_qda_def,
RDA = model_rda_def,
KNN = model_knn_def))
resamps
summary(resamps)
# box plots
bwplot(resamps, metric = "Accuracy")
# box plots
bwplot(resamps, metric = "ROC")
difValues <- diff(resamps)
difValues
summary(difValues)
# intervalos de confianza para las diferencias
dotplot(difValues)
model_knn_def
unlink('index_cache', recursive = TRUE)
setwd("~/OneDrive - Universidad Carlos III de Madrid/Big_Analytics_Ed4/14_15_Aprendizaje_Supervisado_Harold_A_Hdez_Roig/bookdown-Aprendizaje-Supervisado")
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
winsc <- read_csv("data_breast_cancer_Winsconsin.csv")
## Cargar datos ----
winsc <- read_csv("data_breast_cancer_Winsconsin.csv")
View(winsc)
# entender los datos
summary(winsc)
df <- as.data.frame(winsc)
## *** LDA -----
set.seed(123)
train.ID <- createDataPartition(df$diagnosis, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# damos nuestros primeros pasos en la validacion cruzada...
# (podemos probar varias opciones)
# en este caso no hay parametros para tunear
fit_control <- trainControl(method='cv', number = 10)
model_lda_def <- train(diagnosis ~.,
data = train_df,
method = "lda",
trControl = fit_control)
# la respuesta es diagnosis: B = benign, M = malignant
winsc$diagnosis <- as.factor(winsc$diagnosis)
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
winsc <- read_csv("data_breast_cancer_Winsconsin.csv")
# no nos interesan los ID, y la última columna no se ha cargado bien
winsc <- winsc[, 2:32]
# la respuesta es diagnosis: B = benign, M = malignant
winsc$diagnosis <- as.factor(winsc$diagnosis)
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
wiscon <- read_csv("data_breast_cancer_wisconsin.csv")
# no nos interesan los ID, y la última columna no se ha cargado bien
wiscon <- wiscon[, 2:32]
# la respuesta es diagnosis: B = benign, M = malignant
wiscon$diagnosis <- as.factor(wiscon$diagnosis)
str(wiscon)
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
wiscon <- read_csv("data_breast_cancer_wisconsin.csv")
# no nos interesan los ID, y la última columna no se ha cargado bien
wiscon <- wiscon[, 2:32]
# la respuesta es diagnosis: B = benign, M = malignant
wiscon$diagnosis <- as.factor(wiscon$diagnosis)
str(wiscon)
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
wiscon <- read_csv("data_breast_cancer_wisconsin.csv")
# no nos interesan los ID, y la última columna no se ha cargado bien
wiscon <- wiscon[, 2:32]
# la respuesta es diagnosis: B = benign, M = malignant
wiscon$diagnosis <- as.factor(wiscon$diagnosis)
str(wiscon)
library(caret)
library(ggplot2)
library(readr)
library(dplyr)
library(gridExtra)
library(ROCR)
## Cargar datos ----
wiscon <- read_csv("data_breast_cancer_wisconsin.csv")
# no nos interesan los ID, y la última columna no se ha cargado bien
wiscon <- wiscon[, 2:32]
# la respuesta es diagnosis: B = benign, M = malignant
wiscon$diagnosis <- as.factor(wiscon$diagnosis)
df <- as.data.frame(wiscon)
str(df)
set.seed(666)
train.ID <- createDataPartition(df$diagnosis, p = 0.7, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# en este caso estamos reduciendo la cantidad de variables iniciales
# a solamente ¡2!
preProc.res <- preProcess(df, method = c('pca'), pcaComp = 2)
df.pca <- predict(preProc.res, df)
head(df.pca, 7)
ggplot(df.pca,  aes(x = PC1, y = PC2, group = diagnosis)) +
geom_point(aes(color = diagnosis ), alpha = 0.8) +
theme_light()
ggplot(df.pca,  aes(x = PC1, y = PC2, group = diagnosis)) +
geom_point(aes(color = diagnosis ), alpha = 0.8) +
theme_light()
# Ajustemos nuestros modelos con los datos transformados:
train_df <- df.pca[train.ID, ]
test_df <- df.pca[-train.ID, ]
unlink('index_cache', recursive = TRUE)
