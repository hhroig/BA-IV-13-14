summary(iris) # un breve descriptivo
# ver el balance de la muestra, según las clases
prop.table(table(iris$Species))
# visualización
ggpairs(iris, ggplot2::aes(colour = Species, alpha = 0.2), lower=list(combo=wrap("facethist",
bins=round(sqrt(50))))) + theme_light()
iris.scl <- scale(iris[,1:4])
# set de índices para entrenar-validar (80% - 20%)
set.seed(123)
train.ID <- sample(1:nrow(iris), 0.8 * nrow(iris))
# matriz de diseño para entrenar
X.train <- iris.scl[train.ID,1:4]
# matriz de diseño para testear
X.test <- iris.scl[-train.ID,1:4]
# respuesta (categórica) entrenamiento
Y <- iris[train.ID,5]
# respuesta (categórica) test
Y.test <- iris[-train.ID,5]
# KNN
pr <- knn(X.train, X.test, cl=Y, k = round(sqrt(nrow(X.train))))
# matriz de confusión
tab <- table(pr,Y.test)
knitr::kable(
tab, caption = 'Matriz de Confusión - KNN Iris',
booktabs = TRUE)
# tasa de error test
test.error <- sum(pr != Y.test)/sum(tab)
test.error
test.error <- data.frame()
for (K in seq(1, 120, by = 5)) {
# KNN
pr <- knn(X.train,X.test,cl=Y,k=K)
# matriz de confusion
tab <- table(pr,Y.test)
# tasa de error test
test.error <- rbind(test.error,
data.frame(Tasa.Error = sum(pr != Y.test)/sum(tab), K))
}
ggplot(test.error, aes(x = K, y = Tasa.Error)) +
geom_point() +
geom_line() +
ylab("Tasa de Error (test)") +  xlab("K: número de vecinos") +
theme_light()
library(caret)
str(iris)
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "pairs",
## Add a key at the top
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(4,1 ),
auto.key = list(columns = 2))
# creamos una partición test
df <- iris
set.seed(123)
train.ID <- createDataPartition(df$Species, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# primeros pasos con la validación cruzada...
fit_control <- trainControl(method='cv', number = 10)
model_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 10)
model_knn_iris
plot(model_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris <- predict(model_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris, reference = test_df$Species)
# definimos el grid:
some_k <- expand.grid(k = 1:15)
# k-fold CV pero con repeticiones
fit_control1 <- trainControl(
method = "repeatedcv",
number = 10, # número de folds
repeats = 5 ) # repeticiones
# bootstrap
fit_control2 <- trainControl(
method = "boot",
number = 10) # número de muestras bootstrap
# LOOCV
fit_control3 <- trainControl(
method = "LOOCV")
model2_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control2,
preProcess = c("center", "scale"),
tuneGrid = some_k)
model2_knn_iris
plot(model2_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris2 <- predict(model2_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris2, reference = test_df$Species)
varImp(model_knn_iris)
# seleccionamos los predictores que queremos y la respuesta
df_petal <- iris[,c("Petal.Length", "Petal.Width", "Species")]
train_df_petal <- df_petal[train.ID, ]
test_df_petal <- df_petal[-train.ID, ]
# el modelo...
fit_control <- trainControl(method='cv', number = 10)
model_knn_petal <- train(Species ~.,
data = train_df_petal,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 20)
model_knn_petal
plot(model_knn_petal)
# hagamos las predicciones del conjunto de prueba
prediction_knn_petal <- predict(model_knn_petal, newdata = test_df_petal)
confusionMatrix(prediction_knn_petal, reference = test_df_petal$Species)
decision_bound = function(train_df_in, test_df_in, model_in){
# plot decision boundary  for iris[,c("Petal.Length", "Petal.Width", "Species")]
require(MASS)
require(caret)
require(ggplot2)
require(gridExtra)
# Paso 1: crear un grid de valores desde min a max de ambos predictores
pl = seq(min(train_df_in$Petal.Length), max(train_df_in$Petal.Length), length.out = 80)
pw = seq(min(train_df_in$Petal.Width), max(train_df_in$Petal.Width), length.out = 80)
lgrid <- expand.grid(Petal.Length=pl, Petal.Width=pw)
# Paso 2: obtener las predicciones tanto para el grid como para el test
modelPredGrid <- predict(model_in, newdata=lgrid)
train_df_in$Pred.Class <- predict(model_in, newdata = train_df_in)
test_df_in$Pred.Class <- predict(model_in, newdata = test_df_in)
# Paso 3: ggplot con la funcion contour
gg1 <- ggplot(data=lgrid) +
stat_contour(aes(x=Petal.Length, y=Petal.Width, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=Petal.Length, y=Petal.Width, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Train") +
geom_point(data=train_df_in,
aes(x=Petal.Length, y=Petal.Width,
colour=Species), size=5, shape=1) +
theme_light()
gg2 <- ggplot(data=lgrid) +
stat_contour(aes(x=Petal.Length, y=Petal.Width, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=Petal.Length, y=Petal.Width, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Test") +
geom_point(data=test_df_in,
aes(x=Petal.Length, y=Petal.Width,
colour=Species), size=5, shape=1) +
theme_light()
grid.arrange(gg1, gg2, ncol=1, nrow=2)
}
# fronteras de decisión, usando la nueva función
decision_bound(train_df_petal, test_df_petal, model_knn_petal)
library(MASS)
library(caret)
library(ggplot2)
# cargar e inspeccionar los datos
# para detalles sobre las variables predictoras:
# ?Boston
data(Boston)
str(Boston)
summary(Boston)
# ver correlaciones y posibles relaciones:
# todos los predictores:
# ggpairs(Boston, ggplot2::aes(y = medv, alpha = 0.2)) + theme_light()
# algunos predictores:
ggpairs(Boston[, c("lstat", "age", "rad", "rm", "ptratio", "medv")]) + theme_light()
# Split the data into training and test set
set.seed(123)
train.ID <- createDataPartition(Boston$medv, p = 0.8, list = FALSE)
train.data  <- Boston[train.ID, ]
test.data <- Boston[-train.ID, ]
# Fit the model on the training set
set.seed(123)
knn_reg_model <- train(
medv~.,
data = train.data,
method = "knn",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneLength = 20
)
knn_reg_model
# Plot model error RMSE vs different values of k
plot(knn_reg_model)
# predicciones
predictions <- predict(knn_reg_model, test.data)
# RMSE: raíz del error cuadrático medio
RMSE(predictions, test.data$medv)
# MAE: error absoluto medio
MAE(predictions, test.data$medv)
df_plot <- data.frame(pred = predictions, real = test.data$medv)
ggplot(df_plot, aes(x = pred, y = real)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
xlab(expression(hat( y))) + ylab("y") +
theme_light()
# importancia de las variables según impacto en la predicción
varImp(knn_reg_model)
# seleccionemos solo algunas variables:
boston <- Boston[, c("lstat", "rm", "ptratio", "medv")]
# ajustamos el modelo en el nuevo diseño
train.data  <- boston[train.ID, ]
test.data <- boston[-train.ID, ]
set.seed(123)
knn_reg_model <- train(
medv~.,
data = train.data,
method = "knn",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneGrid = expand.grid(k = 1:15)
)
# Veamos si el modelo ha mejorado algo:
# predicciones
predictions <- predict(knn_reg_model, test.data)
# RMSE: raíz del error cuadrático medio
RMSE(predictions, test.data$medv)
# MAE: error absoluto medio
MAE(predictions, test.data$medv)
df_plot <- data.frame(pred = predictions, real = test.data$medv)
ggplot(df_plot, aes(x = pred, y = real)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
xlab(expression(hat( y))) + ylab("y") +
theme_light()
getModelInfo("kknn")
knitr::kable(
head(iris, 10), caption = 'Estructura del dataset Iris',
booktabs = TRUE
)
library(class)
library(ggplot2)
library(GGally)
df <- data(iris) # cargar datos
summary(iris) # un breve descriptivo
# ver el balance de la muestra, según las clases
prop.table(table(iris$Species))
# visualización
ggpairs(iris, ggplot2::aes(colour = Species, alpha = 0.2), lower=list(combo=wrap("facethist",
bins=round(sqrt(50))))) + theme_light()
iris.scl <- scale(iris[,1:4])
# set de índices para entrenar-validar (80% - 20%)
set.seed(123)
train.ID <- sample(1:nrow(iris), 0.8 * nrow(iris))
# matriz de diseño para entrenar
X.train <- iris.scl[train.ID,1:4]
# matriz de diseño para testear
X.test <- iris.scl[-train.ID,1:4]
# respuesta (categórica) entrenamiento
Y <- iris[train.ID,5]
# respuesta (categórica) test
Y.test <- iris[-train.ID,5]
# KNN
pr <- knn(X.train, X.test, cl=Y, k = round(sqrt(nrow(X.train))))
# matriz de confusión
tab <- table(pr,Y.test)
knitr::kable(
tab, caption = 'Matriz de Confusión - KNN Iris',
booktabs = TRUE)
# tasa de error test
test.error <- sum(pr != Y.test)/sum(tab)
test.error
test.error <- data.frame()
for (K in seq(1, 120, by = 5)) {
# KNN
pr <- knn(X.train,X.test,cl=Y,k=K)
# matriz de confusion
tab <- table(pr,Y.test)
# tasa de error test
test.error <- rbind(test.error,
data.frame(Tasa.Error = sum(pr != Y.test)/sum(tab), K))
}
ggplot(test.error, aes(x = K, y = Tasa.Error)) +
geom_point() +
geom_line() +
ylab("Tasa de Error (test)") +  xlab("K: número de vecinos") +
theme_light()
library(caret)
str(iris)
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "pairs",
## Add a key at the top
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(4, 1),
auto.key = list(columns = 3))
featurePlot(x = iris[, 1:4],
y = iris$Species,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(4,1 ),
auto.key = list(columns = 2))
# creamos una partición test
df <- iris
set.seed(123)
train.ID <- createDataPartition(df$Species, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# primeros pasos con la validación cruzada...
fit_control <- trainControl(method='cv', number = 10)
model_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 10)
model_knn_iris
plot(model_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris <- predict(model_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris, reference = test_df$Species)
# definimos el grid:
some_k <- expand.grid(k = 1:15)
# k-fold CV pero con repeticiones
fit_control1 <- trainControl(
method = "repeatedcv",
number = 10, # número de folds
repeats = 5 ) # repeticiones
# bootstrap
fit_control2 <- trainControl(
method = "boot",
number = 10) # número de muestras bootstrap
# LOOCV
fit_control3 <- trainControl(
method = "LOOCV")
model2_knn_iris <- train(Species ~.,
data = train_df,
method = "knn",
trControl = fit_control2,
preProcess = c("center", "scale"),
tuneGrid = some_k)
model2_knn_iris
plot(model2_knn_iris)
# hagamos las predicciones del conjunto de prueba
prediction_knn_iris2 <- predict(model2_knn_iris, newdata = test_df)
confusionMatrix(prediction_knn_iris2, reference = test_df$Species)
varImp(model_knn_iris)
# seleccionamos los predictores que queremos y la respuesta
df_petal <- iris[,c("Petal.Length", "Petal.Width", "Species")]
train_df_petal <- df_petal[train.ID, ]
test_df_petal <- df_petal[-train.ID, ]
# el modelo...
fit_control <- trainControl(method='cv', number = 10)
model_knn_petal <- train(Species ~.,
data = train_df_petal,
method = "knn",
trControl = fit_control,
preProcess = c("center", "scale"),
tuneLength = 20)
model_knn_petal
plot(model_knn_petal)
# hagamos las predicciones del conjunto de prueba
prediction_knn_petal <- predict(model_knn_petal, newdata = test_df_petal)
confusionMatrix(prediction_knn_petal, reference = test_df_petal$Species)
decision_bound = function(train_df_in, test_df_in, model_in){
# plot decision boundary  for iris[,c("Petal.Length", "Petal.Width", "Species")]
require(MASS)
require(caret)
require(ggplot2)
require(gridExtra)
# Paso 1: crear un grid de valores desde min a max de ambos predictores
pl = seq(min(train_df_in$Petal.Length), max(train_df_in$Petal.Length), length.out = 80)
pw = seq(min(train_df_in$Petal.Width), max(train_df_in$Petal.Width), length.out = 80)
lgrid <- expand.grid(Petal.Length=pl, Petal.Width=pw)
# Paso 2: obtener las predicciones tanto para el grid como para el test
modelPredGrid <- predict(model_in, newdata=lgrid)
train_df_in$Pred.Class <- predict(model_in, newdata = train_df_in)
test_df_in$Pred.Class <- predict(model_in, newdata = test_df_in)
# Paso 3: ggplot con la funcion contour
gg1 <- ggplot(data=lgrid) +
stat_contour(aes(x=Petal.Length, y=Petal.Width, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=Petal.Length, y=Petal.Width, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Train") +
geom_point(data=train_df_in,
aes(x=Petal.Length, y=Petal.Width,
colour=Species), size=5, shape=1) +
theme_light()
gg2 <- ggplot(data=lgrid) +
stat_contour(aes(x=Petal.Length, y=Petal.Width, z=as.numeric(modelPredGrid)), bins=2) +
geom_point(aes(x=Petal.Length, y=Petal.Width, colour=modelPredGrid), alpha=0.1) +
labs(colour = "Clases") + ggtitle("Test") +
geom_point(data=test_df_in,
aes(x=Petal.Length, y=Petal.Width,
colour=Species), size=5, shape=1) +
theme_light()
grid.arrange(gg1, gg2, ncol=1, nrow=2)
}
# fronteras de decisión, usando la nueva función
decision_bound(train_df_petal, test_df_petal, model_knn_petal)
library(MASS)
library(caret)
library(ggplot2)
# cargar e inspeccionar los datos
# para detalles sobre las variables predictoras:
# ?Boston
data(Boston)
str(Boston)
summary(Boston)
# ver correlaciones y posibles relaciones:
# todos los predictores:
# ggpairs(Boston, ggplot2::aes(y = medv, alpha = 0.2)) + theme_light()
# algunos predictores:
ggpairs(Boston[, c("lstat", "age", "rad", "rm", "ptratio", "medv")]) + theme_light()
# Split the data into training and test set
set.seed(123)
train.ID <- createDataPartition(Boston$medv, p = 0.8, list = FALSE)
train.data  <- Boston[train.ID, ]
test.data <- Boston[-train.ID, ]
# Fit the model on the training set
set.seed(123)
knn_reg_model <- train(
medv~.,
data = train.data,
method = "knn",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneLength = 20
)
knn_reg_model
# Plot model error RMSE vs different values of k
plot(knn_reg_model)
# predicciones
predictions <- predict(knn_reg_model, test.data)
# RMSE: raíz del error cuadrático medio
RMSE(predictions, test.data$medv)
# MAE: error absoluto medio
MAE(predictions, test.data$medv)
df_plot <- data.frame(pred = predictions, real = test.data$medv)
ggplot(df_plot, aes(x = pred, y = real)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
xlab(expression(hat( y))) + ylab("y") +
theme_light()
# importancia de las variables según impacto en la predicción
varImp(knn_reg_model)
# seleccionemos solo algunas variables:
boston <- Boston[, c("lstat", "rm", "ptratio", "medv")]
# ajustamos el modelo en el nuevo diseño
train.data  <- boston[train.ID, ]
test.data <- boston[-train.ID, ]
set.seed(123)
knn_reg_model <- train(
medv~.,
data = train.data,
method = "knn",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneGrid = expand.grid(k = 1:15)
)
# Veamos si el modelo ha mejorado algo:
# predicciones
predictions <- predict(knn_reg_model, test.data)
# RMSE: raíz del error cuadrático medio
RMSE(predictions, test.data$medv)
# MAE: error absoluto medio
MAE(predictions, test.data$medv)
df_plot <- data.frame(pred = predictions, real = test.data$medv)
ggplot(df_plot, aes(x = pred, y = real)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
xlab(expression(hat( y))) + ylab("y") +
theme_light()
getModelInfo("kknn")
getModelInfo("kknn")$parameters
getModelInfo("kknn")$kknn$parameters
getModelInfo("kknn")$kknn$grid
kerns <- c("rectangular", "triangular", "epanechnikov", "biweight", "triweight",
"cos", "inv", "gaussian")
# muestra, por eso es necesario una particion balanceada con createDataPartition
df <- iris
set.seed(123)
train.ID <- createDataPartition(df$Species, p = 0.8, list = FALSE)
train_df <- df[train.ID, ]
test_df <- df[-train.ID, ]
# hacemos una validación cruzada con 10-folds 10 veces
fit_control <- trainControl(method='repeatedcv', number = 10, repeats = 10)
# fijamos el grid de valores de los hiperparámetros:
buscar_mejor <- expand.grid( kmax =  3:9,
distance = 1:2,
kernel = c("rectangular", #standard knn
"triangular",
"gaussian"))
install.packages("kknn")
unlink('_main_cache', recursive = TRUE)
unlink('index_cache', recursive = TRUE)
unlink('index_cache', recursive = TRUE)
unlink('index_cache', recursive = TRUE)
