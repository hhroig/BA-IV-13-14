<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 K - Vecinos más Próximos | Introducción al Aprendizaje Supervisado</title>
  <meta name="description" content="Big Analytics V" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="2 K - Vecinos más Próximos | Introducción al Aprendizaje Supervisado" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Big Analytics V" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 K - Vecinos más Próximos | Introducción al Aprendizaje Supervisado" />
  
  <meta name="twitter:description" content="Big Analytics V" />
  

<meta name="author" content="Harold A. Hernández-Roig (hahernan@est-econ.uc3m.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="DA.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html"><i class="fa fa-check"></i><b>2</b> K - Vecinos más Próximos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#clasificación-con-el-paquete-class"><i class="fa fa-check"></i><b>2.1</b> Clasificación con el paquete <code>class</code></a></li>
<li class="chapter" data-level="2.2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#el-paquete-caret"><i class="fa fa-check"></i><b>2.2</b> El paquete <code>caret</code></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#visualización"><i class="fa fa-check"></i><b>2.2.1</b> Visualización</a></li>
<li class="chapter" data-level="2.2.2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#clasificación-con-knn"><i class="fa fa-check"></i><b>2.2.2</b> Clasificación con KNN</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>2.3</b> Importancia de las variables</a></li>
<li class="chapter" data-level="2.4" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#regresión"><i class="fa fa-check"></i><b>2.4</b> Regresión</a></li>
<li class="chapter" data-level="2.5" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#weighted-knn"><i class="fa fa-check"></i><b>2.5</b> Weighted KNN</a></li>
<li class="chapter" data-level="2.6" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#procesamiento-en-paralelo"><i class="fa fa-check"></i><b>2.6</b> Procesamiento en paralelo</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="DA.html"><a href="DA.html"><i class="fa fa-check"></i><b>3</b> Análisis Discriminante</a>
<ul>
<li class="chapter" data-level="3.1" data-path="DA.html"><a href="DA.html#LDA"><i class="fa fa-check"></i><b>3.1</b> Análisis Discriminante Lineal</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="DA.html"><a href="DA.html#frontera-de-decisión-en-2d"><i class="fa fa-check"></i><b>3.1.1</b> Frontera de decisión en 2D</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="DA.html"><a href="DA.html#QDA"><i class="fa fa-check"></i><b>3.2</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="3.3" data-path="DA.html"><a href="DA.html#RDA"><i class="fa fa-check"></i><b>3.3</b> Análisis Discriminante Regularizado</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="compara.html"><a href="compara.html"><i class="fa fa-check"></i><b>4</b> Comparación entre Modelos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="compara.html"><a href="compara.html#comparando-según-accuracy"><i class="fa fa-check"></i><b>4.1</b> Comparando según <code>Accuracy</code></a></li>
<li class="chapter" data-level="4.2" data-path="compara.html"><a href="compara.html#curva-roc"><i class="fa fa-check"></i><b>4.2</b> Curva <em>ROC</em></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="compara.html"><a href="compara.html#análisis-en-la-muestra-test"><i class="fa fa-check"></i><b>4.2.1</b> Análisis en la muestra test</a></li>
<li class="chapter" data-level="4.2.2" data-path="compara.html"><a href="compara.html#análisis-en-la-muestra-de-entrenamiento"><i class="fa fa-check"></i><b>4.2.2</b> Análisis en la muestra de entrenamiento</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="wiscon.html"><a href="wiscon.html"><i class="fa fa-check"></i><b>5</b> Wisconsin Breast-Cancer Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="wiscon.html"><a href="wiscon.html#reducción-de-la-dimensión"><i class="fa fa-check"></i><b>5.1</b> Reducción de la dimensión</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción al Aprendizaje Supervisado</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="k---vecinos-más-próximos" class="section level1" number="2">
<h1><span class="header-section-number">2</span> K - Vecinos más Próximos</h1>
<p>Comenzamos con uno de los algoritmos más sencillos e intuitivos para regresión y clasificación: los <em>K - Vecinos Más Próximos</em> (<em>KNN: K-Nearest Neighbors</em>). Nuestro bautizo será con un problema de clasificación, empleando los paquetes <code>class</code> y <code>caret</code>. Luego, pasaremos a un problema sencillo de regresión, esta vez usando solo el paquete <code>caret</code>. Trataremos los problemas de <em>ajuste y validación del modelo</em>, usando técnicas de <em>remuestreo</em>.</p>
<div id="clasificación-con-el-paquete-class" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Clasificación con el paquete <code>class</code></h2>
<p>El problema inicial está relacionado con la clasificación de la especie de flor Iris—<em>setosa</em>, <em>virginica</em> y <em>versicolor</em>—a partir de mediciones sus pétalos y sépalos. Estos datos fueron recogidos por Ronald Fisher con el objetivo de cuantificar la variación morfológica de la flor. Actualmente están disponibles en diversas plataformas. En R es uno de los datos que vienen de base (<code>iris</code>).</p>
<p>En la Tabla <a href="k-vecinos-más-próximos.html#tab:iris-tab">2.1</a> representamos una muestra del dataset, que en su totalidad consiste de 50 observaciones de cada una de las 3 especies. Como todo estudio, debemos comenzar por un análisis descriptivo de la muestra.</p>
<table>
<caption><span id="tab:iris-tab">Table 2.1: </span>Estructura del dataset Iris</caption>
<thead>
<tr class="header">
<th align="right">Sepal.Length</th>
<th align="right">Sepal.Width</th>
<th align="right">Petal.Length</th>
<th align="right">Petal.Width</th>
<th align="left">Species</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5.1</td>
<td align="right">3.5</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td align="right">4.9</td>
<td align="right">3.0</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td align="right">4.7</td>
<td align="right">3.2</td>
<td align="right">1.3</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td align="right">4.6</td>
<td align="right">3.1</td>
<td align="right">1.5</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td align="right">5.0</td>
<td align="right">3.6</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td align="right">5.4</td>
<td align="right">3.9</td>
<td align="right">1.7</td>
<td align="right">0.4</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td align="right">4.6</td>
<td align="right">3.4</td>
<td align="right">1.4</td>
<td align="right">0.3</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td align="right">5.0</td>
<td align="right">3.4</td>
<td align="right">1.5</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="odd">
<td align="right">4.4</td>
<td align="right">2.9</td>
<td align="right">1.4</td>
<td align="right">0.2</td>
<td align="left">setosa</td>
</tr>
<tr class="even">
<td align="right">4.9</td>
<td align="right">3.1</td>
<td align="right">1.5</td>
<td align="right">0.1</td>
<td align="left">setosa</td>
</tr>
</tbody>
</table>
<p>Cargamos las librerías necesarias para llevar a cabo el estudio. Luego inspeccionamos los datos.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="k-vecinos-más-próximos.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ya conocemos esta:</span></span>
<span id="cb1-2"><a href="k-vecinos-más-próximos.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="k-vecinos-más-próximos.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># para usar knn:</span></span>
<span id="cb1-4"><a href="k-vecinos-más-próximos.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb1-5"><a href="k-vecinos-más-próximos.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># esta es nueva para nosotros:</span></span>
<span id="cb1-6"><a href="k-vecinos-más-próximos.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb1-7"><a href="k-vecinos-más-próximos.html#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="k-vecinos-más-próximos.html#cb1-8" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data</span>(iris) <span class="co"># cargar datos</span></span>
<span id="cb1-9"><a href="k-vecinos-más-próximos.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris) <span class="co"># un breve descriptivo</span></span></code></pre></div>
<pre><code>##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
##        Species  
##  setosa    :50  
##  versicolor:50  
##  virginica :50  
##                 
##                 
## </code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="k-vecinos-más-próximos.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ver el balance de la muestra, según las clases</span></span>
<span id="cb3-2"><a href="k-vecinos-más-próximos.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(iris<span class="sc">$</span>Species))</span></code></pre></div>
<pre><code>## 
##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333</code></pre>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="k-vecinos-más-próximos.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visualización</span></span>
<span id="cb5-2"><a href="k-vecinos-más-próximos.html#cb5-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggpairs</span>(iris, </span>
<span id="cb5-3"><a href="k-vecinos-más-próximos.html#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">aes</span>(<span class="at">colour =</span> Species, <span class="at">alpha =</span> <span class="fl">0.2</span>), </span>
<span id="cb5-4"><a href="k-vecinos-más-próximos.html#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>,  <span class="st">&quot;Sepal.Width&quot;</span>, </span>
<span id="cb5-5"><a href="k-vecinos-más-próximos.html#cb5-5" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb5-6"><a href="k-vecinos-más-próximos.html#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb5-7"><a href="k-vecinos-más-próximos.html#cb5-7" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="k-vecinos-más-próximos.html#cb6-1" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggpairs</span>(iris, </span>
<span id="cb6-2"><a href="k-vecinos-más-próximos.html#cb6-2" aria-hidden="true" tabindex="-1"></a>        <span class="fu">aes</span>(<span class="at">colour =</span> Species, <span class="at">alpha =</span> <span class="fl">0.2</span>), </span>
<span id="cb6-3"><a href="k-vecinos-más-próximos.html#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">lower=</span><span class="fu">list</span>(<span class="at">combo=</span><span class="fu">wrap</span>(<span class="st">&quot;facethist&quot;</span>,</span>
<span id="cb6-4"><a href="k-vecinos-más-próximos.html#cb6-4" aria-hidden="true" tabindex="-1"></a>                              <span class="at">bins=</span><span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="dv">50</span>))))) <span class="sc">+</span></span>
<span id="cb6-5"><a href="k-vecinos-más-próximos.html#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb6-6"><a href="k-vecinos-más-próximos.html#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">axis.text.x =</span> <span class="fu">element_text</span>(<span class="at">angle =</span> <span class="dv">45</span>, <span class="at">hjust =</span> <span class="dv">1</span>)) </span>
<span id="cb6-7"><a href="k-vecinos-más-próximos.html#cb6-7" aria-hidden="true" tabindex="-1"></a>p2</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-2-2.png" width="100%" style="display: block; margin: auto;" /></p>
<p>De estos análisis observamos, por ejemplo, que 2 de las 4 variables—<em>Petal.Width</em> y <em>Petal.Length</em>—parecen separar bastante bien las 3 especies, y que la muestra está muy bien balanceada.</p>
<p>Antes de pasar a ajustar nuestro modelo, debemos <em>preprocesar</em> la muestra. El algoritmo <em>KNN</em> es muy sensible a la escala de los datos, por ejemplo, podría favorecer distancias entre elementos con valores más grandes. Una forma sencilla de <em>estandarizar</em> o <em>escalar</em> los datos es usando:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="k-vecinos-más-próximos.html#cb7-1" aria-hidden="true" tabindex="-1"></a>iris.scl <span class="ot">&lt;-</span> <span class="fu">scale</span>(iris[,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span></code></pre></div>
<p>Otro elemento importante es la validación del modelo que ajustemos: ¿cómo y con qué muestra medir la precisión? Por lo pronto, fijaremos aleatoriamente un 20% de los datos para calcular la <em>tasa de error</em>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="k-vecinos-más-próximos.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># set de índices para entrenar-validar (80% - 20%)</span></span>
<span id="cb8-2"><a href="k-vecinos-más-próximos.html#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb8-3"><a href="k-vecinos-más-próximos.html#cb8-3" aria-hidden="true" tabindex="-1"></a>train.ID <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(iris), <span class="fl">0.8</span> <span class="sc">*</span> <span class="fu">nrow</span>(iris)) </span>
<span id="cb8-4"><a href="k-vecinos-más-próximos.html#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="k-vecinos-más-próximos.html#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># matriz de diseño para entrenar</span></span>
<span id="cb8-6"><a href="k-vecinos-más-próximos.html#cb8-6" aria-hidden="true" tabindex="-1"></a>X.train <span class="ot">&lt;-</span> iris.scl[train.ID,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb8-7"><a href="k-vecinos-más-próximos.html#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># matriz de diseño para testear</span></span>
<span id="cb8-8"><a href="k-vecinos-más-próximos.html#cb8-8" aria-hidden="true" tabindex="-1"></a>X.test <span class="ot">&lt;-</span> iris.scl[<span class="sc">-</span>train.ID,<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb8-9"><a href="k-vecinos-más-próximos.html#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># respuesta (categórica) entrenamiento</span></span>
<span id="cb8-10"><a href="k-vecinos-más-próximos.html#cb8-10" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> iris[train.ID,<span class="dv">5</span>]</span>
<span id="cb8-11"><a href="k-vecinos-más-próximos.html#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co"># respuesta (categórica) test</span></span>
<span id="cb8-12"><a href="k-vecinos-más-próximos.html#cb8-12" aria-hidden="true" tabindex="-1"></a>Y.test <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train.ID,<span class="dv">5</span>]</span></code></pre></div>
<p>Usando la función <code>knn</code> podemos predecir las clases de los datos en <code>X.test</code>. Otro problema es cómo seleccionar la cantidad de vecinos <code>k</code> apropiada. Una <em>regla de pulgar</em> (<em>thumb rule</em>) es fijar <span class="math inline">\(k = \sqrt{n_{train}}\)</span>. Para analizar la precisión del modelo creamos la <em>matriz de confusión</em> y calculamos la tasa de error correspondiente para el conjunto de datos test.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="k-vecinos-más-próximos.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># KNN </span></span>
<span id="cb9-2"><a href="k-vecinos-más-próximos.html#cb9-2" aria-hidden="true" tabindex="-1"></a>pr <span class="ot">&lt;-</span> <span class="fu">knn</span>(X.train, X.test, <span class="at">cl=</span>Y, <span class="at">k =</span> <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="fu">nrow</span>(X.train))))</span>
<span id="cb9-3"><a href="k-vecinos-más-próximos.html#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="k-vecinos-más-próximos.html#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># matriz de confusión</span></span>
<span id="cb9-5"><a href="k-vecinos-más-próximos.html#cb9-5" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> <span class="fu">table</span>(pr,Y.test)</span></code></pre></div>
<table>
<caption><span id="tab:confIris-tab">Table 2.2: </span>Matriz de Confusión - KNN Iris</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">setosa</th>
<th align="right">versicolor</th>
<th align="right">virginica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">setosa</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">versicolor</td>
<td align="right">0</td>
<td align="right">14</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">virginica</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="k-vecinos-más-próximos.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tasa de error test</span></span>
<span id="cb10-2"><a href="k-vecinos-más-próximos.html#cb10-2" aria-hidden="true" tabindex="-1"></a>test.error <span class="ot">&lt;-</span> <span class="fu">sum</span>(pr <span class="sc">!=</span> Y.test)<span class="sc">/</span><span class="fu">sum</span>(tab)</span>
<span id="cb10-3"><a href="k-vecinos-más-próximos.html#cb10-3" aria-hidden="true" tabindex="-1"></a>test.error</span></code></pre></div>
<pre><code>## [1] 0.03333333</code></pre>
<p>La tasa de error test es bastante baja, además indica que se clasifican bien el <span class="math inline">\(\approx 97\%\)</span> de las observaciones. Veamos ahora qué pasa al variar el número de vecinos <code>K</code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="k-vecinos-más-próximos.html#cb12-1" aria-hidden="true" tabindex="-1"></a>test.error <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb12-2"><a href="k-vecinos-más-próximos.html#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (K <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">120</span>, <span class="at">by =</span> <span class="dv">5</span>)) {</span>
<span id="cb12-3"><a href="k-vecinos-más-próximos.html#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># KNN</span></span>
<span id="cb12-4"><a href="k-vecinos-más-próximos.html#cb12-4" aria-hidden="true" tabindex="-1"></a>  pr <span class="ot">&lt;-</span> <span class="fu">knn</span>(X.train,X.test,<span class="at">cl=</span>Y,<span class="at">k=</span>K)</span>
<span id="cb12-5"><a href="k-vecinos-más-próximos.html#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># matriz de confusion</span></span>
<span id="cb12-6"><a href="k-vecinos-más-próximos.html#cb12-6" aria-hidden="true" tabindex="-1"></a>  tab <span class="ot">&lt;-</span> <span class="fu">table</span>(pr,Y.test)</span>
<span id="cb12-7"><a href="k-vecinos-más-próximos.html#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># tasa de error test</span></span>
<span id="cb12-8"><a href="k-vecinos-más-próximos.html#cb12-8" aria-hidden="true" tabindex="-1"></a>  test.error <span class="ot">&lt;-</span> <span class="fu">rbind</span>(test.error, </span>
<span id="cb12-9"><a href="k-vecinos-más-próximos.html#cb12-9" aria-hidden="true" tabindex="-1"></a>                        <span class="fu">data.frame</span>(<span class="at">Tasa.Error =</span> <span class="fu">sum</span>(pr <span class="sc">!=</span> Y.test)<span class="sc">/</span><span class="fu">sum</span>(tab), K))</span>
<span id="cb12-10"><a href="k-vecinos-más-próximos.html#cb12-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb12-11"><a href="k-vecinos-más-próximos.html#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="k-vecinos-más-próximos.html#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(test.error, <span class="fu">aes</span>(<span class="at">x =</span> K, <span class="at">y =</span> Tasa.Error)) <span class="sc">+</span> </span>
<span id="cb12-13"><a href="k-vecinos-más-próximos.html#cb12-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb12-14"><a href="k-vecinos-más-próximos.html#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb12-15"><a href="k-vecinos-más-próximos.html#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Tasa de Error (test)&quot;</span>) <span class="sc">+</span>  <span class="fu">xlab</span>(<span class="st">&quot;K: número de vecinos&quot;</span>) <span class="sc">+</span> </span>
<span id="cb12-16"><a href="k-vecinos-más-próximos.html#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-7-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Se representa la tasa de error al aumentar el número de vecinos. Los <em>saltos</em> de la curva son resultado del pequeño tamaño de la muestra test. Como cualquier otro modelo de machine learning, el interés está en seleccionar el nivel de flexibilidad (número de vecinos) que mejore la clasificación… inténtalo!</p>
</div>
<div id="el-paquete-caret" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> El paquete <code>caret</code></h2>
<p>El paquete <code>caret</code> (<em><strong>C</strong>lassification <strong>A</strong>nd <strong>RE</strong>gression <strong>T</strong>raining</em>) es uno de los más populares para entrenar modelos de <em>machine learning</em>. Contiene una interfaz uniforme para la mayoría de los algoritmos que se tratan en este curso y, en particular, los 3 que veremos en estas sesiones. Las ventajas del paquete son que permite hacer:</p>
<ul>
<li>partición de los datos</li>
<li>pre-procesado de los datos</li>
<li>selección de variables</li>
<li>ajuste del modelo usando remuestreo</li>
<li>estimación de la importancia/relevancia de las variables</li>
</ul>
<p>Más información disponible en <a href="http://topepo.github.io/caret/index.html">topepo.github.io/caret</a>.</p>
<div id="visualización" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Visualización</h3>
<p>Seguiremos con los datos <code>iris</code>. El paso inicial: análisis descriptivo y visualización de los datos podríamos obviarlo… pero a modo didáctico reproducimos el mismo análisis, esta vez usando la función <code>featurePlot</code> de <code>caret</code>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="k-vecinos-más-próximos.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="k-vecinos-más-próximos.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iris)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Diagramas de dispersión:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="k-vecinos-más-próximos.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], </span>
<span id="cb19-2"><a href="k-vecinos-más-próximos.html#cb19-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> iris<span class="sc">$</span>Species, </span>
<span id="cb19-3"><a href="k-vecinos-más-próximos.html#cb19-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;pairs&quot;</span>,</span>
<span id="cb19-4"><a href="k-vecinos-más-próximos.html#cb19-4" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Add a key at the top</span></span>
<span id="cb19-5"><a href="k-vecinos-más-próximos.html#cb19-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">3</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Densidades estimadas:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="k-vecinos-más-próximos.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], </span>
<span id="cb20-2"><a href="k-vecinos-más-próximos.html#cb20-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> iris<span class="sc">$</span>Species,</span>
<span id="cb20-3"><a href="k-vecinos-más-próximos.html#cb20-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;density&quot;</span>, </span>
<span id="cb20-4"><a href="k-vecinos-más-próximos.html#cb20-4" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to xyplot() to </span></span>
<span id="cb20-5"><a href="k-vecinos-más-próximos.html#cb20-5" aria-hidden="true" tabindex="-1"></a>            <span class="do">## make it prettier</span></span>
<span id="cb20-6"><a href="k-vecinos-más-próximos.html#cb20-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>), </span>
<span id="cb20-7"><a href="k-vecinos-más-próximos.html#cb20-7" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>)), </span>
<span id="cb20-8"><a href="k-vecinos-más-próximos.html#cb20-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">adjust =</span> <span class="fl">1.5</span>, </span>
<span id="cb20-9"><a href="k-vecinos-más-próximos.html#cb20-9" aria-hidden="true" tabindex="-1"></a>            <span class="at">pch =</span> <span class="st">&quot;|&quot;</span>, </span>
<span id="cb20-10"><a href="k-vecinos-más-próximos.html#cb20-10" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">1</span>), </span>
<span id="cb20-11"><a href="k-vecinos-más-próximos.html#cb20-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">3</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Diagramas de cajas:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="k-vecinos-más-próximos.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">featurePlot</span>(<span class="at">x =</span> iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>], </span>
<span id="cb21-2"><a href="k-vecinos-más-próximos.html#cb21-2" aria-hidden="true" tabindex="-1"></a>            <span class="at">y =</span> iris<span class="sc">$</span>Species, </span>
<span id="cb21-3"><a href="k-vecinos-más-próximos.html#cb21-3" aria-hidden="true" tabindex="-1"></a>            <span class="at">plot =</span> <span class="st">&quot;box&quot;</span>, </span>
<span id="cb21-4"><a href="k-vecinos-más-próximos.html#cb21-4" aria-hidden="true" tabindex="-1"></a>            <span class="do">## Pass in options to bwplot() </span></span>
<span id="cb21-5"><a href="k-vecinos-más-próximos.html#cb21-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">scales =</span> <span class="fu">list</span>(<span class="at">y =</span> <span class="fu">list</span>(<span class="at">relation=</span><span class="st">&quot;free&quot;</span>),</span>
<span id="cb21-6"><a href="k-vecinos-más-próximos.html#cb21-6" aria-hidden="true" tabindex="-1"></a>                          <span class="at">x =</span> <span class="fu">list</span>(<span class="at">rot =</span> <span class="dv">90</span>)),  </span>
<span id="cb21-7"><a href="k-vecinos-más-próximos.html#cb21-7" aria-hidden="true" tabindex="-1"></a>            <span class="at">layout =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">1</span> ), </span>
<span id="cb21-8"><a href="k-vecinos-más-próximos.html#cb21-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">auto.key =</span> <span class="fu">list</span>(<span class="at">columns =</span> <span class="dv">2</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="clasificación-con-knn" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Clasificación con KNN</h3>
<p>Necesitamos extraer una muestra independiente (<em>test</em>) para probar el modelo, una vez ajustado. Ahora usaremos la función <code>createDataPartition</code>, que permite hacer la partición teniendo en cuenta la variable respuesta. Esto es esencial para mantener el balance de la muestra.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="k-vecinos-más-próximos.html#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creamos una partición test</span></span>
<span id="cb22-2"><a href="k-vecinos-más-próximos.html#cb22-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> iris</span>
<span id="cb22-3"><a href="k-vecinos-más-próximos.html#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb22-4"><a href="k-vecinos-más-próximos.html#cb22-4" aria-hidden="true" tabindex="-1"></a>train.ID <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(df<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb22-5"><a href="k-vecinos-más-próximos.html#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="k-vecinos-más-próximos.html#cb22-6" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[train.ID, ]</span>
<span id="cb22-7"><a href="k-vecinos-más-próximos.html#cb22-7" aria-hidden="true" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> df[<span class="sc">-</span>train.ID, ]</span></code></pre></div>
<p>Para ajustar el modelo usaremos la función <code>train</code>, que permite:</p>
<ul>
<li>evaluar, usando remuestreo, el efecto de distintos parámetros en la precisión del modelo;</li>
<li>escoger el modelo óptimo, de acuerdo a los parámetros probados;</li>
<li>estimar la precisión del modelo, de acuerdo a diferentes medidas.</li>
</ul>
<p>Actualmente hay unos <span class="math inline">\(\approx 238\)</span> modelos disponibles. Nosotros empezaremos probando el <code>knn</code>, pero antes tenemos que especificar el método de remuestreo, usando la función <code>trainControl</code>. Con esta función, podemos fijar una validación cruzada <em>k-Fold</em> o <em>leave-one-out (LOOCV)</em>. También están disponibles las opciones <em>bootstrap</em> y <em>k-Fold repetitivo</em>.</p>
<p>En este ejemplo, hemos fijado un <em>k-Fold</em> con 10 hojas. Además, hacemos el escalado de las variables dentro del propio algoritmo, usando la opción <code>preProcess</code>. Finalmente, le decimos al algoritmo que intente 10 valores diferentes para escoger el número de vecinos óptimo, usando la opción <code>tuneLength</code></p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="k-vecinos-más-próximos.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># primeros pasos con la validación cruzada...</span></span>
<span id="cb23-2"><a href="k-vecinos-más-próximos.html#cb23-2" aria-hidden="true" tabindex="-1"></a>fit_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&#39;cv&#39;</span>, <span class="at">number =</span> <span class="dv">10</span>)  </span>
<span id="cb23-3"><a href="k-vecinos-más-próximos.html#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="k-vecinos-más-próximos.html#cb23-4" aria-hidden="true" tabindex="-1"></a>model_knn_iris <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>., </span>
<span id="cb23-5"><a href="k-vecinos-más-próximos.html#cb23-5" aria-hidden="true" tabindex="-1"></a>                       <span class="at">data =</span> train_df, </span>
<span id="cb23-6"><a href="k-vecinos-más-próximos.html#cb23-6" aria-hidden="true" tabindex="-1"></a>                       <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, </span>
<span id="cb23-7"><a href="k-vecinos-más-próximos.html#cb23-7" aria-hidden="true" tabindex="-1"></a>                       <span class="at">trControl =</span> fit_control, </span>
<span id="cb23-8"><a href="k-vecinos-más-próximos.html#cb23-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </span>
<span id="cb23-9"><a href="k-vecinos-más-próximos.html#cb23-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">tuneLength =</span> <span class="dv">10</span>)</span>
<span id="cb23-10"><a href="k-vecinos-más-próximos.html#cb23-10" aria-hidden="true" tabindex="-1"></a>model_knn_iris</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa 
##    5  0.9666667  0.9500
##    7  0.9583333  0.9375
##    9  0.9750000  0.9625
##   11  0.9583333  0.9375
##   13  0.9583333  0.9375
##   15  0.9583333  0.9375
##   17  0.9583333  0.9375
##   19  0.9416667  0.9125
##   21  0.9500000  0.9250
##   23  0.9333333  0.9000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 9.</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="k-vecinos-más-próximos.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_knn_iris)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-13-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Podemos ver en el resumen el número óptimo de vecinos (entre los valores probados) del modelo final. En el gráfico, vemos cómo varía el <em>accuracy</em> en función del número de vecinos. La tabla de confusión y medidas de precisión para los datos test:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="k-vecinos-más-próximos.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hagamos las predicciones del conjunto de prueba</span></span>
<span id="cb26-2"><a href="k-vecinos-más-próximos.html#cb26-2" aria-hidden="true" tabindex="-1"></a>prediction_knn_iris <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_knn_iris, <span class="at">newdata =</span> test_df)</span>
<span id="cb26-3"><a href="k-vecinos-más-próximos.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediction_knn_iris, <span class="at">reference =</span> test_df<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         2
##   virginica       0          0         8
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9333          
##                  95% CI : (0.7793, 0.9918)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 8.747e-12       
##                                           
##                   Kappa : 0.9             
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.8000
## Specificity                 1.0000            0.9000           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              1.0000            1.0000           0.9091
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2667
## Detection Prevalence        0.3333            0.4000           0.2667
## Balanced Accuracy           1.0000            0.9500           0.9000</code></pre>
<p>Intentemos ahora fijar las cantidades de vecinos a probar. También cambiamos el método de remuestreo…</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="k-vecinos-más-próximos.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># definimos el grid:</span></span>
<span id="cb28-2"><a href="k-vecinos-más-próximos.html#cb28-2" aria-hidden="true" tabindex="-1"></a>some_k <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>) </span>
<span id="cb28-3"><a href="k-vecinos-más-próximos.html#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="k-vecinos-más-próximos.html#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># k-fold CV pero con repeticiones</span></span>
<span id="cb28-5"><a href="k-vecinos-más-próximos.html#cb28-5" aria-hidden="true" tabindex="-1"></a>fit_control1 <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb28-6"><a href="k-vecinos-más-próximos.html#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </span>
<span id="cb28-7"><a href="k-vecinos-más-próximos.html#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">10</span>, <span class="co"># número de folds</span></span>
<span id="cb28-8"><a href="k-vecinos-más-próximos.html#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">5</span> ) <span class="co"># repeticiones</span></span>
<span id="cb28-9"><a href="k-vecinos-más-próximos.html#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="k-vecinos-más-próximos.html#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># bootstrap</span></span>
<span id="cb28-11"><a href="k-vecinos-más-próximos.html#cb28-11" aria-hidden="true" tabindex="-1"></a>fit_control2 <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb28-12"><a href="k-vecinos-más-próximos.html#cb28-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;boot&quot;</span>,  </span>
<span id="cb28-13"><a href="k-vecinos-más-próximos.html#cb28-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">10</span>) <span class="co"># número de muestras bootstrap</span></span>
<span id="cb28-14"><a href="k-vecinos-más-próximos.html#cb28-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-15"><a href="k-vecinos-más-próximos.html#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="co"># LOOCV</span></span>
<span id="cb28-16"><a href="k-vecinos-más-próximos.html#cb28-16" aria-hidden="true" tabindex="-1"></a>fit_control3 <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb28-17"><a href="k-vecinos-más-próximos.html#cb28-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;LOOCV&quot;</span>) </span>
<span id="cb28-18"><a href="k-vecinos-más-próximos.html#cb28-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-19"><a href="k-vecinos-más-próximos.html#cb28-19" aria-hidden="true" tabindex="-1"></a>model2_knn_iris <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>., </span>
<span id="cb28-20"><a href="k-vecinos-más-próximos.html#cb28-20" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span> train_df, </span>
<span id="cb28-21"><a href="k-vecinos-más-próximos.html#cb28-21" aria-hidden="true" tabindex="-1"></a>                        <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, </span>
<span id="cb28-22"><a href="k-vecinos-más-próximos.html#cb28-22" aria-hidden="true" tabindex="-1"></a>                        <span class="at">trControl =</span> fit_control2, </span>
<span id="cb28-23"><a href="k-vecinos-más-próximos.html#cb28-23" aria-hidden="true" tabindex="-1"></a>                        <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </span>
<span id="cb28-24"><a href="k-vecinos-más-próximos.html#cb28-24" aria-hidden="true" tabindex="-1"></a>                        <span class="at">tuneGrid =</span> some_k)</span>
<span id="cb28-25"><a href="k-vecinos-más-próximos.html#cb28-25" aria-hidden="true" tabindex="-1"></a>model2_knn_iris</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Bootstrapped (10 reps) 
## Summary of sample sizes: 120, 120, 120, 120, 120, 120, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    1  0.9481717  0.9211545
##    2  0.9475159  0.9196833
##    3  0.9453882  0.9165257
##    4  0.9599231  0.9393154
##    5  0.9665503  0.9492382
##    6  0.9686637  0.9524826
##    7  0.9688968  0.9528083
##    8  0.9596084  0.9388259
##    9  0.9647549  0.9465745
##   10  0.9600366  0.9392605
##   11  0.9624756  0.9431153
##   12  0.9555270  0.9326274
##   13  0.9623479  0.9429620
##   14  0.9439143  0.9151811
##   15  0.9438559  0.9150458
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 7.</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="k-vecinos-más-próximos.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model2_knn_iris)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="k-vecinos-más-próximos.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hagamos las predicciones del conjunto de prueba</span></span>
<span id="cb31-2"><a href="k-vecinos-más-próximos.html#cb31-2" aria-hidden="true" tabindex="-1"></a>prediction_knn_iris2 <span class="ot">&lt;-</span> <span class="fu">predict</span>(model2_knn_iris, <span class="at">newdata =</span> test_df)</span>
<span id="cb31-3"><a href="k-vecinos-más-próximos.html#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediction_knn_iris2, <span class="at">reference =</span> test_df<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         2
##   virginica       0          0         8
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9333          
##                  95% CI : (0.7793, 0.9918)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 8.747e-12       
##                                           
##                   Kappa : 0.9             
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.8000
## Specificity                 1.0000            0.9000           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              1.0000            1.0000           0.9091
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2667
## Detection Prevalence        0.3333            0.4000           0.2667
## Balanced Accuracy           1.0000            0.9500           0.9000</code></pre>
</div>
</div>
<div id="importancia-de-las-variables" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Importancia de las variables</h2>
<p>Para KNN no tenemos un método que permita determinar la relevancia de cada predictor. Por ejemplo, en mínimos cuadrados, sí se puede conducir un test para determinar si cada coeficiente <span class="math inline">\(\beta_i\)</span> del modelo es significativamente distinto de cero. Aún así, <code>caret</code> incorpora la función <code>varImp</code> que da una medida de <em>importancia</em> de cada predictor del problema de clasificación o regresión.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="k-vecinos-más-próximos.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImp</span>(model_knn_iris)</span></code></pre></div>
<pre><code>## ROC curve variable importance
## 
##   variables are sorted by maximum importance across the classes
##              setosa versicolor virginica
## Petal.Width  100.00     100.00     100.0
## Petal.Length 100.00     100.00     100.0
## Sepal.Length  90.80      72.07      90.8
## Sepal.Width   56.32      56.32       0.0</code></pre>
<p>Otra opción es usar la <strong>información mutua</strong> o <strong>transinformación</strong> (MI, del inglés <em>mutual information</em>); una cantidad que mide la dependencia mutua entre dos variables aleatorias, es decir, mide la reducción de la incertidumbre (<em>entropía</em>) de una variable aleatoria, <span class="math inline">\(X\)</span>, debido al conocimiento del valor de otra variable aleatoria <span class="math inline">\(Y\)</span>.</p>
<p>Veamos un ejemplo usando el paquete <code>infotheo</code> (a mayor MI, mayor relación entre variables):</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="k-vecinos-más-próximos.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(infotheo)</span>
<span id="cb35-2"><a href="k-vecinos-más-próximos.html#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="k-vecinos-más-próximos.html#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ?mutinformation</span></span>
<span id="cb35-4"><a href="k-vecinos-más-próximos.html#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="k-vecinos-más-próximos.html#cb35-5" aria-hidden="true" tabindex="-1"></a>dat_MI <span class="ot">&lt;-</span> <span class="fu">discretize</span>(train_df)</span>
<span id="cb35-6"><a href="k-vecinos-más-próximos.html#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="k-vecinos-más-próximos.html#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># MI matrix:</span></span>
<span id="cb35-8"><a href="k-vecinos-más-próximos.html#cb35-8" aria-hidden="true" tabindex="-1"></a>MI <span class="ot">&lt;-</span> <span class="fu">mutinformation</span>(dat_MI, <span class="at">method=</span> <span class="st">&quot;emp&quot;</span>)</span>
<span id="cb35-9"><a href="k-vecinos-más-próximos.html#cb35-9" aria-hidden="true" tabindex="-1"></a>MI</span></code></pre></div>
<pre><code>##              Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
## Sepal.Length    1.3808574   0.1619652    0.5376697   0.4959123 0.4319302
## Sepal.Width     0.1619652   1.3759488    0.1688200   0.2131962 0.2354624
## Petal.Length    0.5376697   0.1688200    1.3860165   0.8172804 0.7718830
## Petal.Width     0.4959123   0.2131962    0.8172804   1.3827305 0.8270975
## Species         0.4319302   0.2354624    0.7718830   0.8270975 1.0986123</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="k-vecinos-más-próximos.html#cb37-1" aria-hidden="true" tabindex="-1"></a>MI <span class="sc">%&gt;%</span> </span>
<span id="cb37-2"><a href="k-vecinos-más-próximos.html#cb37-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb37-3"><a href="k-vecinos-más-próximos.html#cb37-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Variable =</span> <span class="fu">colnames</span>(MI), <span class="at">MI =</span> Species) <span class="sc">%&gt;%</span> </span>
<span id="cb37-4"><a href="k-vecinos-más-próximos.html#cb37-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>(Variable, MI) <span class="sc">%&gt;%</span> </span>
<span id="cb37-5"><a href="k-vecinos-más-próximos.html#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">reorder</span>(Variable, <span class="sc">-</span>MI), <span class="at">y =</span> MI)) <span class="sc">+</span></span>
<span id="cb37-6"><a href="k-vecinos-más-próximos.html#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">alpha=</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb37-7"><a href="k-vecinos-más-próximos.html#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;MI: todas vs. Species&quot;</span>, <span class="at">x =</span> <span class="st">&quot;Variable&quot;</span>) <span class="sc">+</span></span>
<span id="cb37-8"><a href="k-vecinos-más-próximos.html#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>Hay métodos específicos de selección de variables, los más usados dependiendo del modelo (<em>lasso</em>, <em>elastic-net</em>, <em>stepwise selction</em> en modelos generalizados, etc.). Aún así, los resultados obtenidos con el <em>MI</em>, <em>varImp</em> y el análisis descriptivo inicial motivan el estudio del problema al disminuir la dimensión <span class="math inline">\(p = 4\)</span> a <span class="math inline">\(2\)</span>, dejando solo <code>Petal.Length</code> y <code>Petal.Width</code>.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="k-vecinos-más-próximos.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># seleccionamos los predictores que queremos y la respuesta</span></span>
<span id="cb38-2"><a href="k-vecinos-más-próximos.html#cb38-2" aria-hidden="true" tabindex="-1"></a>df_petal <span class="ot">&lt;-</span> iris[,<span class="fu">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>, <span class="st">&quot;Species&quot;</span>)]</span>
<span id="cb38-3"><a href="k-vecinos-más-próximos.html#cb38-3" aria-hidden="true" tabindex="-1"></a>train_df_petal <span class="ot">&lt;-</span> df_petal[train.ID, ]</span>
<span id="cb38-4"><a href="k-vecinos-más-próximos.html#cb38-4" aria-hidden="true" tabindex="-1"></a>test_df_petal <span class="ot">&lt;-</span> df_petal[<span class="sc">-</span>train.ID, ]</span>
<span id="cb38-5"><a href="k-vecinos-más-próximos.html#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="k-vecinos-más-próximos.html#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># el modelo...</span></span>
<span id="cb38-7"><a href="k-vecinos-más-próximos.html#cb38-7" aria-hidden="true" tabindex="-1"></a>fit_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&#39;cv&#39;</span>, <span class="at">number =</span> <span class="dv">10</span>)  </span>
<span id="cb38-8"><a href="k-vecinos-más-próximos.html#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="k-vecinos-más-próximos.html#cb38-9" aria-hidden="true" tabindex="-1"></a>model_knn_petal <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>., </span>
<span id="cb38-10"><a href="k-vecinos-más-próximos.html#cb38-10" aria-hidden="true" tabindex="-1"></a>                        <span class="at">data =</span> train_df_petal, </span>
<span id="cb38-11"><a href="k-vecinos-más-próximos.html#cb38-11" aria-hidden="true" tabindex="-1"></a>                        <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>, </span>
<span id="cb38-12"><a href="k-vecinos-más-próximos.html#cb38-12" aria-hidden="true" tabindex="-1"></a>                        <span class="at">trControl =</span> fit_control, </span>
<span id="cb38-13"><a href="k-vecinos-más-próximos.html#cb38-13" aria-hidden="true" tabindex="-1"></a>                        <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </span>
<span id="cb38-14"><a href="k-vecinos-más-próximos.html#cb38-14" aria-hidden="true" tabindex="-1"></a>                        <span class="at">tuneLength =</span> <span class="dv">20</span>)</span>
<span id="cb38-15"><a href="k-vecinos-más-próximos.html#cb38-15" aria-hidden="true" tabindex="-1"></a>model_knn_petal</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   2 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (2), scaled (2) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa 
##    5  0.9666667  0.9500
##    7  0.9666667  0.9500
##    9  0.9666667  0.9500
##   11  0.9666667  0.9500
##   13  0.9666667  0.9500
##   15  0.9666667  0.9500
##   17  0.9583333  0.9375
##   19  0.9666667  0.9500
##   21  0.9583333  0.9375
##   23  0.9666667  0.9500
##   25  0.9666667  0.9500
##   27  0.9666667  0.9500
##   29  0.9666667  0.9500
##   31  0.9666667  0.9500
##   33  0.9750000  0.9625
##   35  0.9833333  0.9750
##   37  0.9750000  0.9625
##   39  0.9833333  0.9750
##   41  0.9750000  0.9625
##   43  0.9666667  0.9500
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 39.</code></pre>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="k-vecinos-más-próximos.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model_knn_petal)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="k-vecinos-más-próximos.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># hagamos las predicciones del conjunto de prueba</span></span>
<span id="cb41-2"><a href="k-vecinos-más-próximos.html#cb41-2" aria-hidden="true" tabindex="-1"></a>prediction_knn_petal <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_knn_petal, <span class="at">newdata =</span> test_df_petal)</span>
<span id="cb41-3"><a href="k-vecinos-más-próximos.html#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">confusionMatrix</span>(prediction_knn_petal, <span class="at">reference =</span> test_df_petal<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         3
##   virginica       0          0         7
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9             
##                  95% CI : (0.7347, 0.9789)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 1.665e-10       
##                                           
##                   Kappa : 0.85            
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.7000
## Specificity                 1.0000            0.8500           1.0000
## Pos Pred Value              1.0000            0.7692           1.0000
## Neg Pred Value              1.0000            1.0000           0.8696
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2333
## Detection Prevalence        0.3333            0.4333           0.2333
## Balanced Accuracy           1.0000            0.9250           0.8500</code></pre>
<p>Pero, ¿cómo visualizar las fronteras de decisión del método? Ahora que <span class="math inline">\(p = 2\)</span>, podemos representar esto en el plano usando la siguiente función:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="k-vecinos-más-próximos.html#cb43-1" aria-hidden="true" tabindex="-1"></a>decision_bound <span class="ot">=</span> <span class="cf">function</span>(train_df_in, test_df_in, model_in){</span>
<span id="cb43-2"><a href="k-vecinos-más-próximos.html#cb43-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot decision boundary  for iris[,c(&quot;Petal.Length&quot;, &quot;Petal.Width&quot;, &quot;Species&quot;)]</span></span>
<span id="cb43-3"><a href="k-vecinos-más-próximos.html#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="k-vecinos-más-próximos.html#cb43-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(MASS)</span>
<span id="cb43-5"><a href="k-vecinos-más-próximos.html#cb43-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(caret)</span>
<span id="cb43-6"><a href="k-vecinos-más-próximos.html#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(ggplot2)</span>
<span id="cb43-7"><a href="k-vecinos-más-próximos.html#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">require</span>(gridExtra)</span>
<span id="cb43-8"><a href="k-vecinos-más-próximos.html#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="k-vecinos-más-próximos.html#cb43-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Paso 1: crear un grid de valores desde min a max de ambos predictores</span></span>
<span id="cb43-10"><a href="k-vecinos-más-próximos.html#cb43-10" aria-hidden="true" tabindex="-1"></a>  pl <span class="ot">=</span> <span class="fu">seq</span>(<span class="fu">min</span>(train_df_in<span class="sc">$</span>Petal.Length), <span class="fu">max</span>(train_df_in<span class="sc">$</span>Petal.Length), <span class="at">length.out =</span> <span class="dv">80</span>)</span>
<span id="cb43-11"><a href="k-vecinos-más-próximos.html#cb43-11" aria-hidden="true" tabindex="-1"></a>  pw <span class="ot">=</span> <span class="fu">seq</span>(<span class="fu">min</span>(train_df_in<span class="sc">$</span>Petal.Width), <span class="fu">max</span>(train_df_in<span class="sc">$</span>Petal.Width), <span class="at">length.out =</span> <span class="dv">80</span>)</span>
<span id="cb43-12"><a href="k-vecinos-más-próximos.html#cb43-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-13"><a href="k-vecinos-más-próximos.html#cb43-13" aria-hidden="true" tabindex="-1"></a>  lgrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">Petal.Length=</span>pl, <span class="at">Petal.Width=</span>pw)</span>
<span id="cb43-14"><a href="k-vecinos-más-próximos.html#cb43-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-15"><a href="k-vecinos-más-próximos.html#cb43-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Paso 2: obtener las predicciones tanto para el grid como para el test</span></span>
<span id="cb43-16"><a href="k-vecinos-más-próximos.html#cb43-16" aria-hidden="true" tabindex="-1"></a>  modelPredGrid <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_in, <span class="at">newdata=</span>lgrid)</span>
<span id="cb43-17"><a href="k-vecinos-más-próximos.html#cb43-17" aria-hidden="true" tabindex="-1"></a>  train_df_in<span class="sc">$</span>Pred.Class <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_in, <span class="at">newdata =</span> train_df_in)</span>
<span id="cb43-18"><a href="k-vecinos-más-próximos.html#cb43-18" aria-hidden="true" tabindex="-1"></a>  test_df_in<span class="sc">$</span>Pred.Class <span class="ot">&lt;-</span> <span class="fu">predict</span>(model_in, <span class="at">newdata =</span> test_df_in)</span>
<span id="cb43-19"><a href="k-vecinos-más-próximos.html#cb43-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-20"><a href="k-vecinos-más-próximos.html#cb43-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Paso 3: ggplot con la funcion contour</span></span>
<span id="cb43-21"><a href="k-vecinos-más-próximos.html#cb43-21" aria-hidden="true" tabindex="-1"></a>  gg1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>lgrid) <span class="sc">+</span></span>
<span id="cb43-22"><a href="k-vecinos-más-próximos.html#cb43-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_contour</span>(<span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width, <span class="at">z=</span><span class="fu">as.numeric</span>(modelPredGrid)), <span class="at">bins=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb43-23"><a href="k-vecinos-más-próximos.html#cb43-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width, <span class="at">colour=</span>modelPredGrid), <span class="at">alpha=</span><span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb43-24"><a href="k-vecinos-más-próximos.html#cb43-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Train&quot;</span>) <span class="sc">+</span></span>
<span id="cb43-25"><a href="k-vecinos-más-próximos.html#cb43-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data=</span>train_df_in,</span>
<span id="cb43-26"><a href="k-vecinos-más-próximos.html#cb43-26" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width,</span>
<span id="cb43-27"><a href="k-vecinos-más-próximos.html#cb43-27" aria-hidden="true" tabindex="-1"></a>                   <span class="at">colour=</span>Species), <span class="at">size=</span><span class="dv">5</span>, <span class="at">shape=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb43-28"><a href="k-vecinos-más-próximos.html#cb43-28" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_light</span>()</span>
<span id="cb43-29"><a href="k-vecinos-más-próximos.html#cb43-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-30"><a href="k-vecinos-más-próximos.html#cb43-30" aria-hidden="true" tabindex="-1"></a>  gg2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(<span class="at">data=</span>lgrid) <span class="sc">+</span></span>
<span id="cb43-31"><a href="k-vecinos-más-próximos.html#cb43-31" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_contour</span>(<span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width, <span class="at">z=</span><span class="fu">as.numeric</span>(modelPredGrid)), <span class="at">bins=</span><span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb43-32"><a href="k-vecinos-más-próximos.html#cb43-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width, <span class="at">colour=</span>modelPredGrid), <span class="at">alpha=</span><span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb43-33"><a href="k-vecinos-más-próximos.html#cb43-33" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;Test&quot;</span>) <span class="sc">+</span></span>
<span id="cb43-34"><a href="k-vecinos-más-próximos.html#cb43-34" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="at">data=</span>test_df_in,</span>
<span id="cb43-35"><a href="k-vecinos-más-próximos.html#cb43-35" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x=</span>Petal.Length, <span class="at">y=</span>Petal.Width,</span>
<span id="cb43-36"><a href="k-vecinos-más-próximos.html#cb43-36" aria-hidden="true" tabindex="-1"></a>                   <span class="at">colour=</span>Species), <span class="at">size=</span><span class="dv">5</span>, <span class="at">shape=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb43-37"><a href="k-vecinos-más-próximos.html#cb43-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_light</span>()</span>
<span id="cb43-38"><a href="k-vecinos-más-próximos.html#cb43-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">grid.arrange</span>(gg1, gg2, <span class="at">ncol=</span><span class="dv">1</span>, <span class="at">nrow=</span><span class="dv">2</span>)</span>
<span id="cb43-39"><a href="k-vecinos-más-próximos.html#cb43-39" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Así que aplicando esto a nuestros datos de entrenamiento (o los del test) obtenemos las fronteras de decisión:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="k-vecinos-más-próximos.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fronteras de decisión, usando la nueva función</span></span>
<span id="cb44-2"><a href="k-vecinos-más-próximos.html#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="fu">decision_bound</span>(train_df_petal, test_df_petal, model_knn_petal)</span></code></pre></div>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre><code>## Loading required package: gridExtra</code></pre>
<pre><code>## 
## Attaching package: &#39;gridExtra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-22-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="regresión" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Regresión</h2>
<p>Abordamos ahora el problema de regresión con KNN, o sea, la respuesta es cuantitativa-continua. Seguimos usando el paquete <code>caret</code> que tiene implementado el algoritmo y ofrece facilidades para el preprocesado de los datos y la validación del modelo.</p>
<p>Particularmente, atacaremos el problema de predecir el precio medio de las viviendas (<code>medv</code>) en los suburbios de Boston, usando otras 13 variables predictoras.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="k-vecinos-más-próximos.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb51-2"><a href="k-vecinos-más-próximos.html#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb51-3"><a href="k-vecinos-más-próximos.html#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb51-4"><a href="k-vecinos-más-próximos.html#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="k-vecinos-más-próximos.html#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># cargar e inspeccionar los datos</span></span>
<span id="cb51-6"><a href="k-vecinos-más-próximos.html#cb51-6" aria-hidden="true" tabindex="-1"></a><span class="co"># para detalles sobre las variables predictoras:</span></span>
<span id="cb51-7"><a href="k-vecinos-más-próximos.html#cb51-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ?Boston</span></span>
<span id="cb51-8"><a href="k-vecinos-más-próximos.html#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Boston)</span>
<span id="cb51-9"><a href="k-vecinos-más-próximos.html#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Boston)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ black  : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="k-vecinos-más-próximos.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Boston)</span></code></pre></div>
<pre><code>##       crim                zn             indus            chas        
##  Min.   : 0.00632   Min.   :  0.00   Min.   : 0.46   Min.   :0.00000  
##  1st Qu.: 0.08205   1st Qu.:  0.00   1st Qu.: 5.19   1st Qu.:0.00000  
##  Median : 0.25651   Median :  0.00   Median : 9.69   Median :0.00000  
##  Mean   : 3.61352   Mean   : 11.36   Mean   :11.14   Mean   :0.06917  
##  3rd Qu.: 3.67708   3rd Qu.: 12.50   3rd Qu.:18.10   3rd Qu.:0.00000  
##  Max.   :88.97620   Max.   :100.00   Max.   :27.74   Max.   :1.00000  
##       nox               rm             age              dis        
##  Min.   :0.3850   Min.   :3.561   Min.   :  2.90   Min.   : 1.130  
##  1st Qu.:0.4490   1st Qu.:5.886   1st Qu.: 45.02   1st Qu.: 2.100  
##  Median :0.5380   Median :6.208   Median : 77.50   Median : 3.207  
##  Mean   :0.5547   Mean   :6.285   Mean   : 68.57   Mean   : 3.795  
##  3rd Qu.:0.6240   3rd Qu.:6.623   3rd Qu.: 94.08   3rd Qu.: 5.188  
##  Max.   :0.8710   Max.   :8.780   Max.   :100.00   Max.   :12.127  
##       rad              tax           ptratio          black       
##  Min.   : 1.000   Min.   :187.0   Min.   :12.60   Min.   :  0.32  
##  1st Qu.: 4.000   1st Qu.:279.0   1st Qu.:17.40   1st Qu.:375.38  
##  Median : 5.000   Median :330.0   Median :19.05   Median :391.44  
##  Mean   : 9.549   Mean   :408.2   Mean   :18.46   Mean   :356.67  
##  3rd Qu.:24.000   3rd Qu.:666.0   3rd Qu.:20.20   3rd Qu.:396.23  
##  Max.   :24.000   Max.   :711.0   Max.   :22.00   Max.   :396.90  
##      lstat            medv      
##  Min.   : 1.73   Min.   : 5.00  
##  1st Qu.: 6.95   1st Qu.:17.02  
##  Median :11.36   Median :21.20  
##  Mean   :12.65   Mean   :22.53  
##  3rd Qu.:16.95   3rd Qu.:25.00  
##  Max.   :37.97   Max.   :50.00</code></pre>
<p>Veamos las relaciones entre predictores y la variable respuesta (en este ejemplo, solo hemos representado algunas).</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="k-vecinos-más-próximos.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ver correlaciones y posibles relaciones:</span></span>
<span id="cb55-2"><a href="k-vecinos-más-próximos.html#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="k-vecinos-más-próximos.html#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># todos los predictores:</span></span>
<span id="cb55-4"><a href="k-vecinos-más-próximos.html#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ggpairs(Boston, ggplot2::aes(y = medv, alpha = 0.2)) + theme_light()</span></span>
<span id="cb55-5"><a href="k-vecinos-más-próximos.html#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co"># algunos predictores:</span></span>
<span id="cb55-6"><a href="k-vecinos-más-próximos.html#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggpairs</span>(Boston[, <span class="fu">c</span>(<span class="st">&quot;lstat&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;rad&quot;</span>, <span class="st">&quot;rm&quot;</span>, <span class="st">&quot;ptratio&quot;</span>, <span class="st">&quot;medv&quot;</span>)]) <span class="sc">+</span> <span class="fu">theme_light</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-24-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Por ejemplo, es notable la relación lineal entre <code>medv</code> y las variables predictoras <code>rm</code> y <code>lstat</code>. Estas dos corresponden al número medio de habitaciones por vivienda y al ínfimo estatus poblacional, respectivamente.</p>
<p>Ajustemos un modelo de regresión, usando todas las variables y el algoritmo KNN.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="k-vecinos-más-próximos.html#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and test set</span></span>
<span id="cb56-2"><a href="k-vecinos-más-próximos.html#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb56-3"><a href="k-vecinos-más-próximos.html#cb56-3" aria-hidden="true" tabindex="-1"></a>train.ID <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(Boston<span class="sc">$</span>medv, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb56-4"><a href="k-vecinos-más-próximos.html#cb56-4" aria-hidden="true" tabindex="-1"></a>train.data  <span class="ot">&lt;-</span> Boston[train.ID, ]</span>
<span id="cb56-5"><a href="k-vecinos-más-próximos.html#cb56-5" aria-hidden="true" tabindex="-1"></a>test.data <span class="ot">&lt;-</span> Boston[<span class="sc">-</span>train.ID, ]</span>
<span id="cb56-6"><a href="k-vecinos-más-próximos.html#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="k-vecinos-más-próximos.html#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model on the training set</span></span>
<span id="cb56-8"><a href="k-vecinos-más-próximos.html#cb56-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb56-9"><a href="k-vecinos-más-próximos.html#cb56-9" aria-hidden="true" tabindex="-1"></a>knn_reg_model <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb56-10"><a href="k-vecinos-más-próximos.html#cb56-10" aria-hidden="true" tabindex="-1"></a>  medv<span class="sc">~</span>.,</span>
<span id="cb56-11"><a href="k-vecinos-más-próximos.html#cb56-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train.data,</span>
<span id="cb56-12"><a href="k-vecinos-más-próximos.html#cb56-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb56-13"><a href="k-vecinos-más-próximos.html#cb56-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb56-14"><a href="k-vecinos-más-próximos.html#cb56-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>),</span>
<span id="cb56-15"><a href="k-vecinos-más-próximos.html#cb56-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneLength =</span> <span class="dv">20</span></span>
<span id="cb56-16"><a href="k-vecinos-más-próximos.html#cb56-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-17"><a href="k-vecinos-más-próximos.html#cb56-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-18"><a href="k-vecinos-más-próximos.html#cb56-18" aria-hidden="true" tabindex="-1"></a>knn_reg_model</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 407 samples
##  13 predictor
## 
## Pre-processing: centered (13), scaled (13) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 366, 367, 366, 366, 366, 366, ... 
## Resampling results across tuning parameters:
## 
##   k   RMSE      Rsquared   MAE     
##    5  4.446665  0.7748420  2.877705
##    7  4.513433  0.7760351  2.931696
##    9  4.510659  0.7822810  2.961313
##   11  4.557329  0.7806128  2.997708
##   13  4.589419  0.7769459  3.031409
##   15  4.683314  0.7715242  3.108591
##   17  4.727456  0.7658943  3.133048
##   19  4.794512  0.7608152  3.190837
##   21  4.871432  0.7555146  3.242578
##   23  4.896989  0.7568145  3.256753
##   25  4.982893  0.7505900  3.318786
##   27  5.035171  0.7497412  3.356345
##   29  5.099070  0.7472969  3.412470
##   31  5.196655  0.7375974  3.477003
##   33  5.260674  0.7329066  3.507057
##   35  5.320022  0.7310458  3.543261
##   37  5.393032  0.7258230  3.592311
##   39  5.457338  0.7205076  3.643305
##   41  5.500014  0.7178285  3.669332
##   43  5.561854  0.7125909  3.713330
## 
## RMSE was used to select the optimal model using the smallest value.
## The final value used for the model was k = 5.</code></pre>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="k-vecinos-más-próximos.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot model error RMSE vs different values of k</span></span>
<span id="cb58-2"><a href="k-vecinos-más-próximos.html#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(knn_reg_model)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-25-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Ahora, lo que nos interesa es disminuir el Error Cuadrático Medio:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="k-vecinos-más-próximos.html#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predicciones</span></span>
<span id="cb59-2"><a href="k-vecinos-más-próximos.html#cb59-2" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_reg_model, test.data)</span>
<span id="cb59-3"><a href="k-vecinos-más-próximos.html#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE: raíz del error cuadrático medio</span></span>
<span id="cb59-4"><a href="k-vecinos-más-próximos.html#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(predictions, test.data<span class="sc">$</span>medv)</span></code></pre></div>
<pre><code>## [1] 4.762122</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="k-vecinos-más-próximos.html#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MAE: error absoluto medio</span></span>
<span id="cb61-2"><a href="k-vecinos-más-próximos.html#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(predictions, test.data<span class="sc">$</span>medv)</span></code></pre></div>
<pre><code>## [1] 3.050101</code></pre>
<p>Si representamos las predicciones y los valores reales de la variable <code>medv</code>, esperamos que los puntos estén muy cercanos a la recta <span class="math inline">\(Y = X\)</span>.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="k-vecinos-más-próximos.html#cb63-1" aria-hidden="true" tabindex="-1"></a>df_plot <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">pred =</span> predictions, <span class="at">real =</span> test.data<span class="sc">$</span>medv)</span>
<span id="cb63-2"><a href="k-vecinos-más-próximos.html#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_plot, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> real)) <span class="sc">+</span></span>
<span id="cb63-3"><a href="k-vecinos-más-próximos.html#cb63-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb63-4"><a href="k-vecinos-más-próximos.html#cb63-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb63-5"><a href="k-vecinos-más-próximos.html#cb63-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">hat</span>( y))) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;y&quot;</span>) <span class="sc">+</span></span>
<span id="cb63-6"><a href="k-vecinos-más-próximos.html#cb63-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-27-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>¿Será posible mejorar esto? ¿Son todas las variables realmente necesarias? ¿Un grid con valores más pequeños a <span class="math inline">\(K = 5\)</span> podría resultar mejor? Veamos qué tal es el ajuste y las predicciones si nos limitamos a unas pocas variables predictoras.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="k-vecinos-más-próximos.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># importancia de las variables según impacto en la predicción</span></span>
<span id="cb64-2"><a href="k-vecinos-más-próximos.html#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="fu">varImp</span>(knn_reg_model)</span></code></pre></div>
<pre><code>## loess r-squared variable importance
## 
##         Overall
## lstat    100.00
## rm        84.11
## ptratio   35.71
## indus     33.76
## crim      30.80
## tax       30.16
## black     25.33
## nox       24.24
## age       21.19
## rad       18.94
## dis       15.00
## zn        14.23
## chas       0.00</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="k-vecinos-más-próximos.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># seleccionemos solo algunas variables:</span></span>
<span id="cb66-2"><a href="k-vecinos-más-próximos.html#cb66-2" aria-hidden="true" tabindex="-1"></a>boston <span class="ot">&lt;-</span> Boston[, <span class="fu">c</span>(<span class="st">&quot;lstat&quot;</span>, <span class="st">&quot;rm&quot;</span>, <span class="st">&quot;ptratio&quot;</span>, <span class="st">&quot;medv&quot;</span>)]</span></code></pre></div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="k-vecinos-más-próximos.html#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ajustamos el modelo en el nuevo diseño</span></span>
<span id="cb67-2"><a href="k-vecinos-más-próximos.html#cb67-2" aria-hidden="true" tabindex="-1"></a>train.data  <span class="ot">&lt;-</span> boston[train.ID, ]</span>
<span id="cb67-3"><a href="k-vecinos-más-próximos.html#cb67-3" aria-hidden="true" tabindex="-1"></a>test.data <span class="ot">&lt;-</span> boston[<span class="sc">-</span>train.ID, ]</span>
<span id="cb67-4"><a href="k-vecinos-más-próximos.html#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="k-vecinos-más-próximos.html#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb67-6"><a href="k-vecinos-más-próximos.html#cb67-6" aria-hidden="true" tabindex="-1"></a>knn_reg_model <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb67-7"><a href="k-vecinos-más-próximos.html#cb67-7" aria-hidden="true" tabindex="-1"></a>  medv<span class="sc">~</span>.,</span>
<span id="cb67-8"><a href="k-vecinos-más-próximos.html#cb67-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train.data,</span>
<span id="cb67-9"><a href="k-vecinos-más-próximos.html#cb67-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;knn&quot;</span>,</span>
<span id="cb67-10"><a href="k-vecinos-más-próximos.html#cb67-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb67-11"><a href="k-vecinos-más-próximos.html#cb67-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>,<span class="st">&quot;scale&quot;</span>),</span>
<span id="cb67-12"><a href="k-vecinos-más-próximos.html#cb67-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>)</span>
<span id="cb67-13"><a href="k-vecinos-más-próximos.html#cb67-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb67-14"><a href="k-vecinos-más-próximos.html#cb67-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-15"><a href="k-vecinos-más-próximos.html#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Veamos si el modelo ha mejorado algo:</span></span>
<span id="cb67-16"><a href="k-vecinos-más-próximos.html#cb67-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-17"><a href="k-vecinos-más-próximos.html#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="co"># predicciones</span></span>
<span id="cb67-18"><a href="k-vecinos-más-próximos.html#cb67-18" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_reg_model, test.data)</span>
<span id="cb67-19"><a href="k-vecinos-más-próximos.html#cb67-19" aria-hidden="true" tabindex="-1"></a><span class="co"># RMSE: raíz del error cuadrático medio</span></span>
<span id="cb67-20"><a href="k-vecinos-más-próximos.html#cb67-20" aria-hidden="true" tabindex="-1"></a><span class="fu">RMSE</span>(predictions, test.data<span class="sc">$</span>medv)</span></code></pre></div>
<pre><code>## [1] 4.33752</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="k-vecinos-más-próximos.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MAE: error absoluto medio</span></span>
<span id="cb69-2"><a href="k-vecinos-más-próximos.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">MAE</span>(predictions, test.data<span class="sc">$</span>medv)</span></code></pre></div>
<pre><code>## [1] 2.805195</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="k-vecinos-más-próximos.html#cb71-1" aria-hidden="true" tabindex="-1"></a>df_plot <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">pred =</span> predictions, <span class="at">real =</span> test.data<span class="sc">$</span>medv)</span>
<span id="cb71-2"><a href="k-vecinos-más-próximos.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df_plot, <span class="fu">aes</span>(<span class="at">x =</span> pred, <span class="at">y =</span> real)) <span class="sc">+</span></span>
<span id="cb71-3"><a href="k-vecinos-más-próximos.html#cb71-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb71-4"><a href="k-vecinos-más-próximos.html#cb71-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb71-5"><a href="k-vecinos-más-próximos.html#cb71-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(<span class="fu">hat</span>( y))) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&quot;y&quot;</span>) <span class="sc">+</span></span>
<span id="cb71-6"><a href="k-vecinos-más-próximos.html#cb71-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-30-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="weighted-knn" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Weighted KNN</h2>
<p>El método de K-Vecinos Más Próximos Ponderados (WKNN: <em>Weighted K-Nearest Neighbors</em>) es una variante del KNN. El principio básico es el mismo: predecir una respuesta en función de los puntos más cercanos de la muestra. La diferencia es que WKNN da más importancia a los más próximos, dentro de los K prefijados. Esto se logra ponderando o dando pesos a los vecinos.</p>
<p>En <code>caret</code> podemos fijar el método <code>kknn</code> que implementa WKNN, tanto para regresión como para clasificación. Ahora debemos optimizar 3 hiperparámetros:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="k-vecinos-más-próximos.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getModelInfo</span>(<span class="st">&quot;kknn&quot;</span>)<span class="sc">$</span>kknn<span class="sc">$</span>parameters</span></code></pre></div>
<pre><code>##   parameter     class           label
## 1      kmax   numeric Max. #Neighbors
## 2  distance   numeric        Distance
## 3    kernel character          Kernel</code></pre>
<p>El número de vecinos <code>K</code> se corresponde al campo<code>kmax</code>. El campo <code>distance</code> se refiere al order del parámetro <span class="math inline">\(p\)</span> en la <em>Distancia de Minkowski</em>. El <code>kernel</code> es la transformación de los ejes de coordenadas, las opciones son:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="k-vecinos-más-próximos.html#cb74-1" aria-hidden="true" tabindex="-1"></a>kerns <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;rectangular&quot;</span>, <span class="st">&quot;triangular&quot;</span>, <span class="st">&quot;epanechnikov&quot;</span>, <span class="st">&quot;biweight&quot;</span>, <span class="st">&quot;triweight&quot;</span>, </span>
<span id="cb74-2"><a href="k-vecinos-más-próximos.html#cb74-2" aria-hidden="true" tabindex="-1"></a>                                 <span class="st">&quot;cos&quot;</span>, <span class="st">&quot;inv&quot;</span>, <span class="st">&quot;gaussian&quot;</span>)</span></code></pre></div>
<p>Veamos un ejemplo con los datos <code>iris</code>. Empezamos fijando un grid o malla de posibles valores de los hiperparámetros a optimizar:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="k-vecinos-más-próximos.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># muestra, por eso es necesario una particion balanceada con createDataPartition</span></span>
<span id="cb75-2"><a href="k-vecinos-más-próximos.html#cb75-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> iris</span>
<span id="cb75-3"><a href="k-vecinos-más-próximos.html#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb75-4"><a href="k-vecinos-más-próximos.html#cb75-4" aria-hidden="true" tabindex="-1"></a>train.ID <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(df<span class="sc">$</span>Species, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb75-5"><a href="k-vecinos-más-próximos.html#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="k-vecinos-más-próximos.html#cb75-6" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> df[train.ID, ]</span>
<span id="cb75-7"><a href="k-vecinos-más-próximos.html#cb75-7" aria-hidden="true" tabindex="-1"></a>test_df <span class="ot">&lt;-</span> df[<span class="sc">-</span>train.ID, ]</span>
<span id="cb75-8"><a href="k-vecinos-más-próximos.html#cb75-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-9"><a href="k-vecinos-más-próximos.html#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="co"># hacemos una validación cruzada con 10-folds 10 veces</span></span>
<span id="cb75-10"><a href="k-vecinos-más-próximos.html#cb75-10" aria-hidden="true" tabindex="-1"></a>fit_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&#39;repeatedcv&#39;</span>, <span class="at">number =</span> <span class="dv">10</span>, <span class="at">repeats =</span> <span class="dv">10</span>)</span>
<span id="cb75-11"><a href="k-vecinos-más-próximos.html#cb75-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-12"><a href="k-vecinos-más-próximos.html#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="co"># fijamos el grid de valores de los hiperparámetros:</span></span>
<span id="cb75-13"><a href="k-vecinos-más-próximos.html#cb75-13" aria-hidden="true" tabindex="-1"></a>buscar_mejor <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>( <span class="at">kmax =</span>  <span class="dv">3</span><span class="sc">:</span><span class="dv">9</span>,</span>
<span id="cb75-14"><a href="k-vecinos-más-próximos.html#cb75-14" aria-hidden="true" tabindex="-1"></a>                             <span class="at">distance =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>,</span>
<span id="cb75-15"><a href="k-vecinos-más-próximos.html#cb75-15" aria-hidden="true" tabindex="-1"></a>                             <span class="at">kernel =</span> <span class="fu">c</span>(<span class="st">&quot;rectangular&quot;</span>, <span class="co">#standard knn</span></span>
<span id="cb75-16"><a href="k-vecinos-más-próximos.html#cb75-16" aria-hidden="true" tabindex="-1"></a>                                        <span class="st">&quot;triangular&quot;</span>,</span>
<span id="cb75-17"><a href="k-vecinos-más-próximos.html#cb75-17" aria-hidden="true" tabindex="-1"></a>                                        <span class="st">&quot;gaussian&quot;</span>))</span></code></pre></div>
<p>El modelo se ajusta igual a como ya hemos estudiado:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="k-vecinos-más-próximos.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb76-2"><a href="k-vecinos-más-próximos.html#cb76-2" aria-hidden="true" tabindex="-1"></a>model.w.knn <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>.,</span>
<span id="cb76-3"><a href="k-vecinos-más-próximos.html#cb76-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> train_df,</span>
<span id="cb76-4"><a href="k-vecinos-más-próximos.html#cb76-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">&quot;kknn&quot;</span>,</span>
<span id="cb76-5"><a href="k-vecinos-más-próximos.html#cb76-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> fit_control,</span>
<span id="cb76-6"><a href="k-vecinos-más-próximos.html#cb76-6" aria-hidden="true" tabindex="-1"></a>                     <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb76-7"><a href="k-vecinos-más-próximos.html#cb76-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tuneGrid =</span> buscar_mejor)</span>
<span id="cb76-8"><a href="k-vecinos-más-próximos.html#cb76-8" aria-hidden="true" tabindex="-1"></a>model.w.knn</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   kmax  distance  kernel       Accuracy   Kappa  
##   3     1         rectangular  0.9600000  0.94000
##   3     1         triangular   0.9558333  0.93375
##   3     1         gaussian     0.9583333  0.93750
##   3     2         rectangular  0.9508333  0.92625
##   3     2         triangular   0.9550000  0.93250
##   3     2         gaussian     0.9483333  0.92250
##   4     1         rectangular  0.9600000  0.94000
##   4     1         triangular   0.9558333  0.93375
##   4     1         gaussian     0.9583333  0.93750
##   4     2         rectangular  0.9491667  0.92375
##   4     2         triangular   0.9550000  0.93250
##   4     2         gaussian     0.9458333  0.91875
##   5     1         rectangular  0.9575000  0.93625
##   5     1         triangular   0.9558333  0.93375
##   5     1         gaussian     0.9583333  0.93750
##   5     2         rectangular  0.9400000  0.91000
##   5     2         triangular   0.9566667  0.93500
##   5     2         gaussian     0.9591667  0.93875
##   6     1         rectangular  0.9575000  0.93625
##   6     1         triangular   0.9558333  0.93375
##   6     1         gaussian     0.9550000  0.93250
##   6     2         rectangular  0.9416667  0.91250
##   6     2         triangular   0.9558333  0.93375
##   6     2         gaussian     0.9558333  0.93375
##   7     1         rectangular  0.9550000  0.93250
##   7     1         triangular   0.9558333  0.93375
##   7     1         gaussian     0.9558333  0.93375
##   7     2         rectangular  0.9433333  0.91500
##   7     2         triangular   0.9575000  0.93625
##   7     2         gaussian     0.9558333  0.93375
##   8     1         rectangular  0.9550000  0.93250
##   8     1         triangular   0.9558333  0.93375
##   8     1         gaussian     0.9558333  0.93375
##   8     2         rectangular  0.9433333  0.91500
##   8     2         triangular   0.9616667  0.94250
##   8     2         gaussian     0.9583333  0.93750
##   9     1         rectangular  0.9550000  0.93250
##   9     1         triangular   0.9558333  0.93375
##   9     1         gaussian     0.9558333  0.93375
##   9     2         rectangular  0.9450000  0.91750
##   9     2         triangular   0.9675000  0.95125
##   9     2         gaussian     0.9608333  0.94125
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were kmax = 9, distance = 2 and kernel
##  = triangular.</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="k-vecinos-más-próximos.html#cb78-1" aria-hidden="true" tabindex="-1"></a>model.w.knn<span class="sc">$</span>finalModel</span></code></pre></div>
<pre><code>## 
## Call:
## kknn::train.kknn(formula = .outcome ~ ., data = dat, kmax = param$kmax,     distance = param$distance, kernel = as.character(param$kernel))
## 
## Type of response variable: nominal
## Minimal misclassification: 0.01666667
## Best kernel: triangular
## Best k: 9</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="k-vecinos-más-próximos.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model.w.knn)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-35-1.png" width="80%" style="display: block; margin: auto;" />
Observamos que el modelo final—el mejor de acuerdo al <code>Accuracy</code>—es aquel con 8 vecinos, donde el parámetro <span class="math inline">\(p=2\)</span> en la Distancia de Minkowski (equivalente a la Distancia Euclídea) y el kernel es triangular. Esto se obtuvo al probar 7 valores de <code>kmax</code> <span class="math inline">\(\times\)</span> 2 valores de <code>distance</code> <span class="math inline">\(\times\)</span> 3 posibles <code>kernel</code>.</p>
<p>Por otro lado, en lugar de escribir explícitamente el grid de valores a probar, en <code>caret</code> tenemos la opción de realizar una búsqueda aleatoria. Esto podría ser un primer paso para detectar rangos de valores de los hiperparámetros donde luego afinar la búsqueda. Como ejemplo, lo haremos para solo 8 combinaciones de posibles hiperparámetros (en la práctica debemos fijar un mayor número de combinaciones, lo que conlleva un mayor coste computacional):</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="k-vecinos-más-próximos.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># random search WKNN</span></span>
<span id="cb81-2"><a href="k-vecinos-más-próximos.html#cb81-2" aria-hidden="true" tabindex="-1"></a>fit_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&#39;repeatedcv&#39;</span>, <span class="at">number =</span> <span class="dv">10</span>, </span>
<span id="cb81-3"><a href="k-vecinos-más-próximos.html#cb81-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">repeats =</span> <span class="dv">10</span>,</span>
<span id="cb81-4"><a href="k-vecinos-más-próximos.html#cb81-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">search =</span> <span class="st">&quot;random&quot;</span>)</span>
<span id="cb81-5"><a href="k-vecinos-más-próximos.html#cb81-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb81-6"><a href="k-vecinos-más-próximos.html#cb81-6" aria-hidden="true" tabindex="-1"></a>model.w.knn <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>.,</span>
<span id="cb81-7"><a href="k-vecinos-más-próximos.html#cb81-7" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> train_df,</span>
<span id="cb81-8"><a href="k-vecinos-más-próximos.html#cb81-8" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">&quot;kknn&quot;</span>,</span>
<span id="cb81-9"><a href="k-vecinos-más-próximos.html#cb81-9" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> fit_control,</span>
<span id="cb81-10"><a href="k-vecinos-más-próximos.html#cb81-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb81-11"><a href="k-vecinos-más-próximos.html#cb81-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tuneLength =</span> <span class="dv">8</span>)</span>
<span id="cb81-12"><a href="k-vecinos-más-próximos.html#cb81-12" aria-hidden="true" tabindex="-1"></a>model.w.knn</span></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   kmax  distance   kernel        Accuracy   Kappa  
##    1    0.8715102  biweight      0.9566667  0.93500
##   10    1.9213770  cos           0.9658333  0.94875
##   22    0.6048966  epanechnikov  0.9541667  0.93125
##   25    1.7765156  triangular    0.9683333  0.95250
##   28    1.8982141  inv           0.9666667  0.95000
##   37    0.1352608  rectangular   0.9491667  0.92375
##   37    2.2990154  inv           0.9725000  0.95875
##   40    1.2107700  triangular    0.9583333  0.93750
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were kmax = 37, distance = 2.299015
##  and kernel = inv.</code></pre>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="k-vecinos-más-próximos.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(model.w.knn)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="procesamiento-en-paralelo" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> Procesamiento en paralelo</h2>
<p>No cambia la estructura de entrenamiento, solo es necesario fijar el número de núcleos. En este caso tenemos un ejemplo donde comparamos una ejecución sin paralelizar y otra que emplea 8 núcleos en paralelo con el paquete <code>doParallel</code>. El número de hiperparámetros es 16.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="k-vecinos-más-próximos.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># random search WKNN</span></span>
<span id="cb84-2"><a href="k-vecinos-más-próximos.html#cb84-2" aria-hidden="true" tabindex="-1"></a>fit_control <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method=</span><span class="st">&#39;repeatedcv&#39;</span>, <span class="at">number =</span> <span class="dv">16</span>, </span>
<span id="cb84-3"><a href="k-vecinos-más-próximos.html#cb84-3" aria-hidden="true" tabindex="-1"></a>                            <span class="at">repeats =</span> <span class="dv">10</span>,</span>
<span id="cb84-4"><a href="k-vecinos-más-próximos.html#cb84-4" aria-hidden="true" tabindex="-1"></a>                            <span class="at">search =</span> <span class="st">&quot;random&quot;</span>)</span>
<span id="cb84-5"><a href="k-vecinos-más-próximos.html#cb84-5" aria-hidden="true" tabindex="-1"></a><span class="do">## No-Parallel ----</span></span>
<span id="cb84-6"><a href="k-vecinos-más-próximos.html#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>(<span class="st">&quot;wknn-train&quot;</span>)</span>
<span id="cb84-7"><a href="k-vecinos-más-próximos.html#cb84-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-8"><a href="k-vecinos-más-próximos.html#cb84-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb84-9"><a href="k-vecinos-más-próximos.html#cb84-9" aria-hidden="true" tabindex="-1"></a>model.w.knn <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>.,</span>
<span id="cb84-10"><a href="k-vecinos-más-próximos.html#cb84-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> train_df,</span>
<span id="cb84-11"><a href="k-vecinos-más-próximos.html#cb84-11" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">&quot;kknn&quot;</span>,</span>
<span id="cb84-12"><a href="k-vecinos-más-próximos.html#cb84-12" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> fit_control,</span>
<span id="cb84-13"><a href="k-vecinos-más-próximos.html#cb84-13" aria-hidden="true" tabindex="-1"></a>                     <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb84-14"><a href="k-vecinos-más-próximos.html#cb84-14" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tuneLength =</span> <span class="dv">16</span>)</span>
<span id="cb84-15"><a href="k-vecinos-más-próximos.html#cb84-15" aria-hidden="true" tabindex="-1"></a>time_wknn <span class="ot">&lt;-</span> <span class="fu">toc</span>()</span>
<span id="cb84-16"><a href="k-vecinos-más-próximos.html#cb84-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-17"><a href="k-vecinos-más-próximos.html#cb84-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Parallel ----</span></span>
<span id="cb84-18"><a href="k-vecinos-más-próximos.html#cb84-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-19"><a href="k-vecinos-más-próximos.html#cb84-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb84-20"><a href="k-vecinos-más-próximos.html#cb84-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-21"><a href="k-vecinos-más-próximos.html#cb84-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Número de núcleos:</span></span>
<span id="cb84-22"><a href="k-vecinos-más-próximos.html#cb84-22" aria-hidden="true" tabindex="-1"></a>cl <span class="ot">&lt;-</span> <span class="fu">makePSOCKcluster</span>(<span class="dv">8</span>)</span>
<span id="cb84-23"><a href="k-vecinos-más-próximos.html#cb84-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-24"><a href="k-vecinos-más-próximos.html#cb84-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Registrar:</span></span>
<span id="cb84-25"><a href="k-vecinos-más-próximos.html#cb84-25" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cl)</span>
<span id="cb84-26"><a href="k-vecinos-más-próximos.html#cb84-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-27"><a href="k-vecinos-más-próximos.html#cb84-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Misma estructura que hasta ahora:</span></span>
<span id="cb84-28"><a href="k-vecinos-más-próximos.html#cb84-28" aria-hidden="true" tabindex="-1"></a><span class="fu">tic</span>(<span class="st">&quot;wknn-train_para&quot;</span>)</span>
<span id="cb84-29"><a href="k-vecinos-más-próximos.html#cb84-29" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb84-30"><a href="k-vecinos-más-próximos.html#cb84-30" aria-hidden="true" tabindex="-1"></a>model.w.knn <span class="ot">&lt;-</span> <span class="fu">train</span>(Species <span class="sc">~</span>.,</span>
<span id="cb84-31"><a href="k-vecinos-más-próximos.html#cb84-31" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> train_df,</span>
<span id="cb84-32"><a href="k-vecinos-más-próximos.html#cb84-32" aria-hidden="true" tabindex="-1"></a>                     <span class="at">method =</span> <span class="st">&quot;kknn&quot;</span>,</span>
<span id="cb84-33"><a href="k-vecinos-más-próximos.html#cb84-33" aria-hidden="true" tabindex="-1"></a>                     <span class="at">trControl =</span> fit_control,</span>
<span id="cb84-34"><a href="k-vecinos-más-próximos.html#cb84-34" aria-hidden="true" tabindex="-1"></a>                     <span class="at">preProcess =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),</span>
<span id="cb84-35"><a href="k-vecinos-más-próximos.html#cb84-35" aria-hidden="true" tabindex="-1"></a>                     <span class="at">tuneLength =</span> <span class="dv">16</span>)</span>
<span id="cb84-36"><a href="k-vecinos-más-próximos.html#cb84-36" aria-hidden="true" tabindex="-1"></a>time_wknn_para <span class="ot">&lt;-</span> <span class="fu">toc</span>()</span>
<span id="cb84-37"><a href="k-vecinos-más-próximos.html#cb84-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-38"><a href="k-vecinos-más-próximos.html#cb84-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-39"><a href="k-vecinos-más-próximos.html#cb84-39" aria-hidden="true" tabindex="-1"></a><span class="fu">stopImplicitCluster</span>()</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="DA.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
