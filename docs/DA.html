<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Análisis Discriminante | Introducción al Aprendizaje Supervisado</title>
  <meta name="description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Análisis Discriminante | Introducción al Aprendizaje Supervisado" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Análisis Discriminante | Introducción al Aprendizaje Supervisado" />
  
  <meta name="twitter:description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento." />
  

<meta name="author" content="Harold A. Hernández-Roig (hahernan@est-econ.uc3m.es)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="k-vecinos-más-próximos.html"/>
<link rel="next" href="compara.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html"><i class="fa fa-check"></i><b>2</b> K - Vecinos más Próximos</a><ul>
<li class="chapter" data-level="2.1" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#clasificación-con-el-paquete-class"><i class="fa fa-check"></i><b>2.1</b> Clasificación con el paquete <code>class</code></a></li>
<li class="chapter" data-level="2.2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#el-paquete-caret"><i class="fa fa-check"></i><b>2.2</b> El paquete <code>caret</code></a><ul>
<li class="chapter" data-level="2.2.1" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#visualización"><i class="fa fa-check"></i><b>2.2.1</b> Visualización</a></li>
<li class="chapter" data-level="2.2.2" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#clasificación-con-knn"><i class="fa fa-check"></i><b>2.2.2</b> Clasificación con KNN</a></li>
<li class="chapter" data-level="2.2.3" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>2.2.3</b> Importancia de las variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#regresión"><i class="fa fa-check"></i><b>2.3</b> Regresión</a></li>
<li class="chapter" data-level="2.4" data-path="k-vecinos-más-próximos.html"><a href="k-vecinos-más-próximos.html#weighted-knn"><i class="fa fa-check"></i><b>2.4</b> Weighted KNN</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="DA.html"><a href="DA.html"><i class="fa fa-check"></i><b>3</b> Análisis Discriminante</a><ul>
<li class="chapter" data-level="3.1" data-path="DA.html"><a href="DA.html#LDA"><i class="fa fa-check"></i><b>3.1</b> Análisis Discriminante Lineal</a></li>
<li class="chapter" data-level="3.2" data-path="DA.html"><a href="DA.html#QDA"><i class="fa fa-check"></i><b>3.2</b> Análisis Discriminante Cuadrático</a></li>
<li class="chapter" data-level="3.3" data-path="DA.html"><a href="DA.html#RDA"><i class="fa fa-check"></i><b>3.3</b> Análisis Discriminante Regularizado</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="compara.html"><a href="compara.html"><i class="fa fa-check"></i><b>4</b> Comparación entre Modelos</a><ul>
<li class="chapter" data-level="4.1" data-path="compara.html"><a href="compara.html#comparando-según-accuracy"><i class="fa fa-check"></i><b>4.1</b> Comparando según <code>Accuracy</code></a></li>
<li class="chapter" data-level="4.2" data-path="compara.html"><a href="compara.html#curva-roc"><i class="fa fa-check"></i><b>4.2</b> Curva <em>ROC</em></a><ul>
<li class="chapter" data-level="4.2.1" data-path="compara.html"><a href="compara.html#análisis-en-la-muestra-test"><i class="fa fa-check"></i><b>4.2.1</b> Análisis en la muestra test</a></li>
<li class="chapter" data-level="4.2.2" data-path="compara.html"><a href="compara.html#análisis-en-la-muestra-de-entrenamiento"><i class="fa fa-check"></i><b>4.2.2</b> Análisis en la muestra de entrenamiento</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="wiscon.html"><a href="wiscon.html"><i class="fa fa-check"></i><b>5</b> Wisconsin Breast-Cancer Data</a><ul>
<li class="chapter" data-level="5.1" data-path="wiscon.html"><a href="wiscon.html#comentarios-finales-reducción-de-la-dimensión"><i class="fa fa-check"></i><b>5.1</b> Comentarios finales: reducción de la dimensión</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introducción al Aprendizaje Supervisado</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="DA" class="section level1">
<h1><span class="header-section-number">3</span> Análisis Discriminante</h1>
<p>En esta sección nos concentramos en el problema de clasificación. Particularmente, estudiaremos los métodos de <em>Análisis Discriminante Lineal (LDA)</em>, <em>Cuadrático (QDA)</em> y <em>Regularizado (RDA)</em>. Usaremos el conjunto de datos <code>Default</code> del paquete <code>ISLR</code>:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" title="1"><span class="kw">library</span>(caret)</a>
<a class="sourceLine" id="cb74-2" title="2"><span class="kw">library</span>(ISLR)</a>
<a class="sourceLine" id="cb74-3" title="3"></a>
<a class="sourceLine" id="cb74-4" title="4"><span class="kw">data</span>(<span class="st">&quot;Default&quot;</span>)</a>
<a class="sourceLine" id="cb74-5" title="5"><span class="kw">head</span>(Default, <span class="dv">10</span>)</a></code></pre></div>
<pre><code>##    default student   balance    income
## 1       No      No  729.5265 44361.625
## 2       No     Yes  817.1804 12106.135
## 3       No      No 1073.5492 31767.139
## 4       No      No  529.2506 35704.494
## 5       No      No  785.6559 38463.496
## 6       No     Yes  919.5885  7491.559
## 7       No      No  825.5133 24905.227
## 8       No     Yes  808.6675 17600.451
## 9       No      No 1161.0579 37468.529
## 10      No      No    0.0000 29275.268</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" title="1"><span class="kw">str</span>(Default)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    10000 obs. of  4 variables:
##  $ default: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ student: Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 1 2 1 1 1 2 1 2 1 1 ...
##  $ balance: num  730 817 1074 529 786 ...
##  $ income : num  44362 12106 31767 35704 38463 ...</code></pre>
<p>El objetivo es predecir si un sujeto de la muestre fallará en el pago de su tarjeta de crédito. Por tanto, la variable respuesta es <code>default</code>, categórica con solo los niveles <code>Yes</code> y <code>No</code>. Tenemos información sobre el balance mensual de crédito en <code>balance</code>, el salario anual en <code>income</code> y si es estudiante o no en <code>student</code>. Solo un <span class="math inline">\(3\%\)</span> de la muestra (<span class="math inline">\(n = 10000\)</span>), así que es una muestra muy desbalanceada.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" title="1"><span class="kw">summary</span>(Default)</a></code></pre></div>
<pre><code>##  default    student       balance           income     
##  No :9667   No :7056   Min.   :   0.0   Min.   :  772  
##  Yes: 333   Yes:2944   1st Qu.: 481.7   1st Qu.:21340  
##                        Median : 823.6   Median :34553  
##                        Mean   : 835.4   Mean   :33517  
##                        3rd Qu.:1166.3   3rd Qu.:43808  
##                        Max.   :2654.3   Max.   :73554</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" title="1"><span class="co"># ver el balance de la muestra</span></a>
<a class="sourceLine" id="cb80-2" title="2"><span class="kw">prop.table</span>(<span class="kw">table</span>(Default<span class="op">$</span>default))</a></code></pre></div>
<pre><code>## 
##     No    Yes 
## 0.9667 0.0333</code></pre>
<p>Nos concentramos en predecir <code>default</code> a partir de las variables predictoras <code>balance</code> e <code>income</code>. En el siguiente diagrama de dispersión se observa cierto solapamiento entre las clases a predecir, pero una clara diferenciación de acuerdo a la variable <code>balance</code>.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb82-1" title="1"><span class="kw">library</span>(ggplot2)</a>
<a class="sourceLine" id="cb82-2" title="2"><span class="kw">library</span>(gridExtra)</a>
<a class="sourceLine" id="cb82-3" title="3"></a>
<a class="sourceLine" id="cb82-4" title="4"><span class="co">## Scatter plot con densidades ----</span></a>
<a class="sourceLine" id="cb82-5" title="5">plot<span class="fl">.2</span>d &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Default, <span class="kw">aes</span>(<span class="dt">x =</span> balance, <span class="dt">y =</span> income, <span class="dt">group =</span> default)) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-6" title="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">shape =</span> default, <span class="dt">color =</span> default), <span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-7" title="7"><span class="st">  </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb82-8" title="8"></a>
<a class="sourceLine" id="cb82-9" title="9"><span class="co"># Empty plot</span></a>
<a class="sourceLine" id="cb82-10" title="10">empty &lt;-<span class="st"> </span><span class="kw">ggplot</span>()<span class="op">+</span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">color=</span><span class="st">&quot;white&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-11" title="11"><span class="st">  </span><span class="kw">theme</span>(</a>
<a class="sourceLine" id="cb82-12" title="12">    <span class="dt">plot.background =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-13" title="13">    <span class="dt">panel.grid.major =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-14" title="14">    <span class="dt">panel.grid.minor =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-15" title="15">    <span class="dt">panel.border =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-16" title="16">    <span class="dt">panel.background =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-17" title="17">    <span class="dt">axis.title.x =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-18" title="18">    <span class="dt">axis.title.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-19" title="19">    <span class="dt">axis.text.x =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-20" title="20">    <span class="dt">axis.text.y =</span> <span class="kw">element_blank</span>(),</a>
<a class="sourceLine" id="cb82-21" title="21">    <span class="dt">axis.ticks =</span> <span class="kw">element_blank</span>()</a>
<a class="sourceLine" id="cb82-22" title="22">  )</a>
<a class="sourceLine" id="cb82-23" title="23"><span class="co"># arriba</span></a>
<a class="sourceLine" id="cb82-24" title="24">dens.balance &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Default, <span class="kw">aes</span>(<span class="dt">x =</span> balance, <span class="dt">group =</span> default)) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-25" title="25"><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> default, <span class="dt">fill =</span> default), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-26" title="26"><span class="st">  </span><span class="kw">theme_light</span>()<span class="op">+</span></a>
<a class="sourceLine" id="cb82-27" title="27"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a>
<a class="sourceLine" id="cb82-28" title="28"><span class="co"># derecha</span></a>
<a class="sourceLine" id="cb82-29" title="29">dens.income &lt;-<span class="st"> </span><span class="kw">ggplot</span>(Default, <span class="kw">aes</span>(<span class="dt">x =</span> income, <span class="dt">group =</span> default)) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-30" title="30"><span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">color =</span> default, <span class="dt">fill =</span> default), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb82-31" title="31"><span class="st">  </span><span class="kw">theme_light</span>() <span class="op">+</span><span class="st"> </span><span class="kw">coord_flip</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb82-32" title="32"><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</a>
<a class="sourceLine" id="cb82-33" title="33"></a>
<a class="sourceLine" id="cb82-34" title="34"><span class="kw">grid.arrange</span>(dens.balance, empty, plot<span class="fl">.2</span>d, dens.income, <span class="dt">ncol=</span><span class="dv">2</span>, <span class="dt">nrow=</span><span class="dv">2</span>, <span class="dt">widths=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">1</span>), <span class="dt">heights=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-38-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div id="LDA" class="section level2">
<h2><span class="header-section-number">3.1</span> Análisis Discriminante Lineal</h2>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" title="1">df &lt;-<span class="st"> </span>Default[, <span class="kw">c</span>(<span class="st">&quot;income&quot;</span>, <span class="st">&quot;balance&quot;</span>, <span class="st">&quot;default&quot;</span>)]</a>
<a class="sourceLine" id="cb83-2" title="2"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb83-3" title="3">train.ID &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df<span class="op">$</span>default, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb83-4" title="4"></a>
<a class="sourceLine" id="cb83-5" title="5">train_df &lt;-<span class="st"> </span>df[train.ID, ]</a>
<a class="sourceLine" id="cb83-6" title="6">test_df &lt;-<span class="st"> </span>df[<span class="op">-</span>train.ID, ]</a>
<a class="sourceLine" id="cb83-7" title="7"></a>
<a class="sourceLine" id="cb83-8" title="8"><span class="co"># definimos como control una validación cruzada con 10 hojas, sin repeticiones</span></a>
<a class="sourceLine" id="cb83-9" title="9">fit_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb83-10" title="10"></a>
<a class="sourceLine" id="cb83-11" title="11"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb83-12" title="12">model_lda_def &lt;-<span class="st"> </span><span class="kw">train</span>(default <span class="op">~</span>.,</a>
<a class="sourceLine" id="cb83-13" title="13">                       <span class="dt">data =</span> train_df,</a>
<a class="sourceLine" id="cb83-14" title="14">                       <span class="dt">method =</span> <span class="st">&quot;lda&quot;</span>,</a>
<a class="sourceLine" id="cb83-15" title="15">                       <span class="dt">trControl =</span> fit_control)</a>
<a class="sourceLine" id="cb83-16" title="16">model_lda_def</a></code></pre></div>
<pre><code>## Linear Discriminant Analysis 
## 
## 8001 samples
##    2 predictor
##    2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 7200, 7200, 7201, 7202, 7201, 7202, ... 
## Resampling results:
## 
##   Accuracy  Kappa    
##   0.973379  0.3710518</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" title="1">model_lda_def<span class="op">$</span>finalModel</a></code></pre></div>
<pre><code>## Call:
## lda(x, grouping = y)
## 
## Prior probabilities of groups:
##         No        Yes 
## 0.96662917 0.03337083 
## 
## Group means:
##       income   balance
## No  33513.73  805.9109
## Yes 32450.16 1753.3628
## 
## Coefficients of linear discriminants:
##                  LD1
## income  9.334558e-06
## balance 2.233976e-03</code></pre>
<p>La precisión durante el entrenamiento es de un <span class="math inline">\(\approx 97\%\)</span>. También vemos que las probabilidades a priori <span class="math inline">\(\pi_i, i = 1,2\)</span> de pertenecer a cada clase son aproximadamente <span class="math inline">\(97\%\)</span> y <span class="math inline">\(3\%\)</span> respectivamente, lo cual corresponde a la razón de fallo que se comenta al inicio. El resultado <code>Coefficients of linear discriminants</code> indica las constantes que se multiplican a cada elemento de la muestra <span class="math inline">\((\text{income}_i, \text{balance}_i)\)</span>, <span class="math inline">\(i = 1, \ldots, n_{\text{train}}\)</span>, para obtener su correspondiente valor de la <em>función discriminante lineal</em>:
<span class="math display">\[ \delta_k(x) = x^T \Sigma^{-1} \mu_k  - \dfrac{1}{2} \mu_k^T \Sigma^{-1} \mu_k+ log(\pi_k) \]</span>
Todo indica que la variable <code>balance</code> tiene un mayor peso en la discriminación. Como alternativa, podemos comprobarlo usando <code>varImp</code>:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" title="1"><span class="kw">varImp</span>(model_lda_def)</a></code></pre></div>
<pre><code>## ROC curve variable importance
## 
##         Importance
## balance        100
## income           0</code></pre>
<p>Veamos ahora qué tal es el ajuste en los datos test.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" title="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb89-2" title="2">prediction_lda_def &lt;-<span class="st"> </span><span class="kw">predict</span>(model_lda_def, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb89-3" title="3"><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  1927   54
##        Yes    6   12
##                                          
##                Accuracy : 0.97           
##                  95% CI : (0.9615, 0.977)
##     No Information Rate : 0.967          
##     P-Value [Acc &gt; NIR] : 0.2488         
##                                          
##                   Kappa : 0.2755         
##                                          
##  Mcnemar&#39;s Test P-Value : 1.298e-09      
##                                          
##             Sensitivity : 0.9969         
##             Specificity : 0.1818         
##          Pos Pred Value : 0.9727         
##          Neg Pred Value : 0.6667         
##              Prevalence : 0.9670         
##          Detection Rate : 0.9640         
##    Detection Prevalence : 0.9910         
##       Balanced Accuracy : 0.5894         
##                                          
##        &#39;Positive&#39; Class : No             
## </code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="co"># extraemos el Accuracy o Precisión</span></a>
<a class="sourceLine" id="cb91-2" title="2"><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## Accuracy 
## 0.969985</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" title="1"><span class="co"># la tasa de error</span></a>
<a class="sourceLine" id="cb93-2" title="2">tasa.error.lda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb93-3" title="3"><span class="kw">names</span>(tasa.error.lda) &lt;-<span class="st"> &quot;Error LDA&quot;</span></a>
<a class="sourceLine" id="cb93-4" title="4">tasa.error.lda</a></code></pre></div>
<pre><code>##  Error LDA 
## 0.03001501</code></pre>
<p>Como estamos en un problema de clasificación en dos dimensiones (<span class="math inline">\(p = 2\)</span>), es posible representar la frontera de decisión del algoritmo, usando la función <code>decision_bound</code>. Debemos modificar los campos para que coincidan con las variables de <code>Default</code>:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" title="1">decision_bound =<span class="st"> </span><span class="cf">function</span>(train_df_in, test_df_in, model_in){</a>
<a class="sourceLine" id="cb95-2" title="2">  <span class="co"># plot decision boundary  for df &lt;- Default[, c(&quot;income&quot;, &quot;balance&quot;, &quot;default&quot;)]</span></a>
<a class="sourceLine" id="cb95-3" title="3"></a>
<a class="sourceLine" id="cb95-4" title="4">  <span class="kw">require</span>(MASS)</a>
<a class="sourceLine" id="cb95-5" title="5">  <span class="kw">require</span>(caret)</a>
<a class="sourceLine" id="cb95-6" title="6">  <span class="kw">require</span>(ggplot2)</a>
<a class="sourceLine" id="cb95-7" title="7">  <span class="kw">require</span>(gridExtra)</a>
<a class="sourceLine" id="cb95-8" title="8"></a>
<a class="sourceLine" id="cb95-9" title="9">  <span class="co"># Paso 1: crear un grid de valores desde min a max de ambos predictores</span></a>
<a class="sourceLine" id="cb95-10" title="10">  pl =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>balance), <span class="kw">max</span>(train_df_in<span class="op">$</span>balance), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb95-11" title="11">  pw =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>income), <span class="kw">max</span>(train_df_in<span class="op">$</span>income), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb95-12" title="12"></a>
<a class="sourceLine" id="cb95-13" title="13">  lgrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">balance=</span>pl, <span class="dt">income=</span>pw)</a>
<a class="sourceLine" id="cb95-14" title="14"></a>
<a class="sourceLine" id="cb95-15" title="15">  <span class="co"># Paso 2: obtener las predicciones tanto para el grid como para el test</span></a>
<a class="sourceLine" id="cb95-16" title="16">  modelPredGrid &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata=</span>lgrid)</a>
<a class="sourceLine" id="cb95-17" title="17">  train_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> train_df_in)</a>
<a class="sourceLine" id="cb95-18" title="18">  test_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> test_df_in)</a>
<a class="sourceLine" id="cb95-19" title="19"></a>
<a class="sourceLine" id="cb95-20" title="20">  <span class="co"># Paso 3: ggplot con la funcion contour</span></a>
<a class="sourceLine" id="cb95-21" title="21">  gg1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-22" title="22"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-23" title="23"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-24" title="24"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Train&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-25" title="25"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>train_df_in,</a>
<a class="sourceLine" id="cb95-26" title="26">               <span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income,</a>
<a class="sourceLine" id="cb95-27" title="27">                   <span class="dt">colour=</span>default), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-28" title="28"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb95-29" title="29"></a>
<a class="sourceLine" id="cb95-30" title="30">  gg2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-31" title="31"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-32" title="32"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-33" title="33"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Test&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-34" title="34"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>test_df_in,</a>
<a class="sourceLine" id="cb95-35" title="35">               <span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income,</a>
<a class="sourceLine" id="cb95-36" title="36">                   <span class="dt">colour=</span>default), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-37" title="37"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb95-38" title="38">  <span class="kw">grid.arrange</span>(gg1, gg2, <span class="dt">ncol=</span><span class="dv">1</span>, <span class="dt">nrow=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb95-39" title="39">}</a></code></pre></div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1"><span class="kw">decision_bound</span>(train_df, test_df, model_lda_def)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-43-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="QDA" class="section level2">
<h2><span class="header-section-number">3.2</span> Análisis Discriminante Cuadrático</h2>
<p>El ajuste para el modelo QDA lo hacemos con el mismo control y la misma partición de la muestra.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb97-2" title="2">model_qda_def &lt;-<span class="st"> </span><span class="kw">train</span>(default <span class="op">~</span>.,</a>
<a class="sourceLine" id="cb97-3" title="3">                       <span class="dt">data =</span> train_df,</a>
<a class="sourceLine" id="cb97-4" title="4">                       <span class="dt">method =</span> <span class="st">&quot;qda&quot;</span>,</a>
<a class="sourceLine" id="cb97-5" title="5">                       <span class="dt">trControl =</span> fit_control)</a>
<a class="sourceLine" id="cb97-6" title="6">model_qda_def</a></code></pre></div>
<pre><code>## Quadratic Discriminant Analysis 
## 
## 8001 samples
##    2 predictor
##    2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 7200, 7200, 7201, 7202, 7201, 7202, ... 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.9730043  0.3787741</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1">model_qda_def<span class="op">$</span>finalModel</a></code></pre></div>
<pre><code>## Call:
## qda(x, grouping = y)
## 
## Prior probabilities of groups:
##         No        Yes 
## 0.96662917 0.03337083 
## 
## Group means:
##       income   balance
## No  33513.73  805.9109
## Yes 32450.16 1753.3628</code></pre>
<p>Los resultados al entrenar son similares al caso LDA. Veamos las predicciones para la muestra test.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb101-2" title="2">prediction_qda_def &lt;-<span class="st"> </span><span class="kw">predict</span>(model_qda_def, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb101-3" title="3"><span class="kw">confusionMatrix</span>(prediction_qda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  1924   51
##        Yes    9   15
##                                          
##                Accuracy : 0.97           
##                  95% CI : (0.9615, 0.977)
##     No Information Rate : 0.967          
##     P-Value [Acc &gt; NIR] : 0.2488         
##                                          
##                   Kappa : 0.3214         
##                                          
##  Mcnemar&#39;s Test P-Value : 1.203e-07      
##                                          
##             Sensitivity : 0.9953         
##             Specificity : 0.2273         
##          Pos Pred Value : 0.9742         
##          Neg Pred Value : 0.6250         
##              Prevalence : 0.9670         
##          Detection Rate : 0.9625         
##    Detection Prevalence : 0.9880         
##       Balanced Accuracy : 0.6113         
##                                          
##        &#39;Positive&#39; Class : No             
## </code></pre>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb103-1" title="1"><span class="co"># extraemos el Accuracy o Precisión</span></a>
<a class="sourceLine" id="cb103-2" title="2"><span class="kw">confusionMatrix</span>(prediction_qda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## Accuracy 
## 0.969985</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb105-1" title="1"><span class="co"># la tasa de error</span></a>
<a class="sourceLine" id="cb105-2" title="2">tasa.error.qda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">confusionMatrix</span>(prediction_qda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb105-3" title="3"><span class="kw">names</span>(tasa.error.qda) &lt;-<span class="st"> &quot;Error QDA&quot;</span></a>
<a class="sourceLine" id="cb105-4" title="4">tasa.error.qda</a></code></pre></div>
<pre><code>##  Error QDA 
## 0.03001501</code></pre>
<p>Tampoco se logran mejorar los resultados. Finalmente, representamos la frontera de decisión del algoritmo.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb107-1" title="1"><span class="kw">decision_bound</span>(train_df, test_df, model_qda_def)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-46-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>¡Ahora observamos que las regiones están separadas por curvas, en lugar de la recta del LDA!</p>
</div>
<div id="RDA" class="section level2">
<h2><span class="header-section-number">3.3</span> Análisis Discriminante Regularizado</h2>
<p><strong>Opción 1</strong>: el paquete <code>caret</code> crea el grid para <span class="math inline">\((\lambda, \gamma)\)</span>:</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" title="1"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb108-2" title="2">model_rda_def &lt;-<span class="st"> </span><span class="kw">train</span>(default <span class="op">~</span>.,</a>
<a class="sourceLine" id="cb108-3" title="3">                       <span class="dt">data =</span> train_df,</a>
<a class="sourceLine" id="cb108-4" title="4">                       <span class="dt">method =</span> <span class="st">&quot;rda&quot;</span>,</a>
<a class="sourceLine" id="cb108-5" title="5">                       <span class="dt">tuneLength =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb108-6" title="6">                       <span class="dt">trControl =</span> fit_control)</a>
<a class="sourceLine" id="cb108-7" title="7"></a>
<a class="sourceLine" id="cb108-8" title="8">model_rda_def</a></code></pre></div>
<pre><code>## Regularized Discriminant Analysis 
## 
## 8001 samples
##    2 predictor
##    2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 7200, 7200, 7201, 7202, 7201, 7202, ... 
## Resampling results across tuning parameters:
## 
##   gamma  lambda  Accuracy   Kappa    
##   0      0       0.9730043  0.3787741
##   0      1       0.9733790  0.3710518
##   1      0       0.9666297  0.0000000
##   1      1       0.9666297  0.0000000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0 and lambda = 1.</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" title="1">model_rda_def<span class="op">$</span>finalModel</a></code></pre></div>
<pre><code>## Call: 
## rda.default(x = x, grouping = y, gamma = param$gamma, lambda = param$lambda)
## 
## Regularization parameters: 
##  gamma lambda 
##      0      1 
## 
## Prior probabilities of groups: 
##         No        Yes 
## 0.96662917 0.03337083 
## 
## Misclassification rate: 
##        apparent: 2.662 %</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" title="1"><span class="co"># en este caso el ggplot nos da información sobre los </span></a>
<a class="sourceLine" id="cb112-2" title="2"><span class="co"># hiperparametros y su correspondiente Accuracy</span></a>
<a class="sourceLine" id="cb112-3" title="3"><span class="kw">ggplot</span>(model_rda_def) <span class="op">+</span><span class="st"> </span><span class="kw">theme_light</span>()</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-48-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><strong>Opción 2</strong>: podemos proporcionar un grid predefinido de valores <span class="math inline">\((\lambda, \gamma)\)</span> en un <code>data.frame</code> que le pasamos a <code>tuneGrid</code>:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" title="1"><span class="co"># el grid se puede definir tambien &quot;a mano&quot;</span></a>
<a class="sourceLine" id="cb113-2" title="2">mi.grid &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">lambda =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.3</span>, <span class="fl">0.6</span>, <span class="dv">1</span>) , </a>
<a class="sourceLine" id="cb113-3" title="3">                       <span class="dt">gamma =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))</a>
<a class="sourceLine" id="cb113-4" title="4"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb113-5" title="5">model_rda_def &lt;-<span class="st"> </span><span class="kw">train</span>(default <span class="op">~</span>.,</a>
<a class="sourceLine" id="cb113-6" title="6">                       <span class="dt">data =</span> train_df,</a>
<a class="sourceLine" id="cb113-7" title="7">                       <span class="dt">method =</span> <span class="st">&quot;rda&quot;</span>,</a>
<a class="sourceLine" id="cb113-8" title="8">                       <span class="dt">tuneGrid =</span> mi.grid,</a>
<a class="sourceLine" id="cb113-9" title="9">                       <span class="dt">trControl =</span> fit_control)</a>
<a class="sourceLine" id="cb113-10" title="10">model_rda_def</a></code></pre></div>
<pre><code>## Regularized Discriminant Analysis 
## 
## 8001 samples
##    2 predictor
##    2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 7200, 7200, 7201, 7202, 7201, 7202, ... 
## Resampling results across tuning parameters:
## 
##   lambda  Accuracy   Kappa    
##   0.0     0.9730043  0.3787741
##   0.3     0.9733790  0.3791078
##   0.6     0.9735039  0.3764691
##   1.0     0.9733790  0.3710518
## 
## Tuning parameter &#39;gamma&#39; was held constant at a value of 0
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were gamma = 0 and lambda = 0.6.</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb115-1" title="1">model_rda_def<span class="op">$</span>finalModel</a></code></pre></div>
<pre><code>## Call: 
## rda.default(x = x, grouping = y, gamma = param$gamma, lambda = param$lambda)
## 
## Regularization parameters: 
##  gamma lambda 
##    0.0    0.6 
## 
## Prior probabilities of groups: 
##         No        Yes 
## 0.96662917 0.03337083 
## 
## Misclassification rate: 
##        apparent: 2.675 %</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb117-1" title="1"><span class="co"># en este caso el ggplot nos da información sobre los </span></a>
<a class="sourceLine" id="cb117-2" title="2"><span class="co"># hiperparametros y su correspondiente Accuracy</span></a>
<a class="sourceLine" id="cb117-3" title="3"><span class="kw">ggplot</span>(model_rda_def) <span class="op">+</span><span class="st"> </span><span class="kw">theme_light</span>()</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-50-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Los resultados indican que los hiperparámetros óptimos en este caso corresponden a <span class="math inline">\((\lambda, \gamma) = (0.6, 0)\)</span>. Esto que hemos hecho es comparar diferentes modelos (porque han sido ajustados con diferentes hiperparámetros) resultantes del mismo algoritmo. Veamos las predicciones para la muestra test, la tasa de error correspondiente y la frontera de decisión.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb118-1" title="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb118-2" title="2">prediction_rda_def &lt;-<span class="st"> </span><span class="kw">predict</span>(model_rda_def, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb118-3" title="3"><span class="kw">confusionMatrix</span>(prediction_rda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  1926   52
##        Yes    7   14
##                                           
##                Accuracy : 0.9705          
##                  95% CI : (0.9621, 0.9775)
##     No Information Rate : 0.967           
##     P-Value [Acc &gt; NIR] : 0.2098          
##                                           
##                   Kappa : 0.3109          
##                                           
##  Mcnemar&#39;s Test P-Value : 1.014e-08       
##                                           
##             Sensitivity : 0.9964          
##             Specificity : 0.2121          
##          Pos Pred Value : 0.9737          
##          Neg Pred Value : 0.6667          
##              Prevalence : 0.9670          
##          Detection Rate : 0.9635          
##    Detection Prevalence : 0.9895          
##       Balanced Accuracy : 0.6042          
##                                           
##        &#39;Positive&#39; Class : No              
## </code></pre>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" title="1"><span class="co"># extraemos el Accuracy o Precisión</span></a>
<a class="sourceLine" id="cb120-2" title="2"><span class="kw">confusionMatrix</span>(prediction_rda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>##  Accuracy 
## 0.9704852</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" title="1"><span class="co"># la tasa de error</span></a>
<a class="sourceLine" id="cb122-2" title="2">tasa.error.rda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">confusionMatrix</span>(prediction_rda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb122-3" title="3"><span class="kw">names</span>(tasa.error.rda) &lt;-<span class="st"> &quot;Error RDA&quot;</span></a>
<a class="sourceLine" id="cb122-4" title="4">tasa.error.rda</a></code></pre></div>
<pre><code>##  Error RDA 
## 0.02951476</code></pre>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" title="1"><span class="kw">decision_bound</span>(train_df, test_df, model_rda_def)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-52-1.png" width="80%" style="display: block; margin: auto;" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="k-vecinos-más-próximos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="compara.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
