<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="3.1 Análisis Discriminante Lineal | Introducción al Aprendizaje Supervisado" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento." />


<meta name="author" content="Harold A. Hernández-Roig (hahernan@est-econ.uc3m.es)" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento.">

<title>3.1 Análisis Discriminante Lineal | Introducción al Aprendizaje Supervisado</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introducción"><span class="toc-section-number">1</span> Introducción</a></li>
<li class="has-sub"><a href="2-k-vecinos-más-próximos.html#k---vecinos-más-próximos"><span class="toc-section-number">2</span> K - Vecinos más Próximos</a><ul>
<li><a href="2-1-clasificación-con-el-paquete-class.html#clasificación-con-el-paquete-class"><span class="toc-section-number">2.1</span> Clasificación con el paquete <code>class</code></a></li>
<li class="has-sub"><a href="2-2-el-paquete-caret.html#el-paquete-caret"><span class="toc-section-number">2.2</span> El paquete <code>caret</code></a><ul>
<li><a href="2-2-el-paquete-caret.html#visualización"><span class="toc-section-number">2.2.1</span> Visualización</a></li>
<li><a href="2-2-el-paquete-caret.html#clasificación-con-knn"><span class="toc-section-number">2.2.2</span> Clasificación con KNN</a></li>
<li><a href="2-2-el-paquete-caret.html#importancia-de-las-variables"><span class="toc-section-number">2.2.3</span> Importancia de las variables</a></li>
</ul></li>
<li><a href="2-3-regresión.html#regresión"><span class="toc-section-number">2.3</span> Regresión</a></li>
<li><a href="2-4-weighted-knn.html#weighted-knn"><span class="toc-section-number">2.4</span> Weighted KNN</a></li>
</ul></li>
<li class="has-sub"><a href="3-DA.html#DA"><span class="toc-section-number">3</span> Análisis Discriminante</a><ul>
<li><a href="3-1-LDA.html#LDA"><span class="toc-section-number">3.1</span> Análisis Discriminante Lineal</a></li>
<li><a href="3-2-QDA.html#QDA"><span class="toc-section-number">3.2</span> Análisis Discriminante Cuadrático</a></li>
<li><a href="3-3-RDA.html#RDA"><span class="toc-section-number">3.3</span> Análisis Discriminante Regularizado</a></li>
</ul></li>
<li class="has-sub"><a href="4-compara.html#compara"><span class="toc-section-number">4</span> Comparación entre Modelos</a><ul>
<li><a href="4-1-comparando-según-accuracy.html#comparando-según-accuracy"><span class="toc-section-number">4.1</span> Comparando según <code>Accuracy</code></a></li>
<li class="has-sub"><a href="4-2-curva-roc.html#curva-roc"><span class="toc-section-number">4.2</span> Curva <em>ROC</em></a><ul>
<li><a href="4-2-curva-roc.html#análisis-en-la-muestra-test"><span class="toc-section-number">4.2.1</span> Análisis en la muestra test</a></li>
<li><a href="4-2-curva-roc.html#análisis-en-la-muestra-de-entrenamiento"><span class="toc-section-number">4.2.2</span> Análisis en la muestra de entrenamiento</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="5-wiscon.html#wiscon"><span class="toc-section-number">5</span> Wisconsin Breast-Cancer Data</a><ul>
<li><a href="5-1-comentarios-finales-reducción-de-la-dimensión.html#comentarios-finales-reducción-de-la-dimensión"><span class="toc-section-number">5.1</span> Comentarios finales: reducción de la dimensión</a></li>
</ul></li>
<li><a href="bibliografía.html#bibliografía">Bibliografía</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="LDA" class="section level2">
<h2><span class="header-section-number">3.1</span> Análisis Discriminante Lineal</h2>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb83-1" data-line-number="1">df &lt;-<span class="st"> </span>Default[, <span class="kw">c</span>(<span class="st">&quot;income&quot;</span>, <span class="st">&quot;balance&quot;</span>, <span class="st">&quot;default&quot;</span>)]</a>
<a class="sourceLine" id="cb83-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb83-3" data-line-number="3">train.ID &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df<span class="op">$</span>default, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb83-4" data-line-number="4"></a>
<a class="sourceLine" id="cb83-5" data-line-number="5">train_df &lt;-<span class="st"> </span>df[train.ID, ]</a>
<a class="sourceLine" id="cb83-6" data-line-number="6">test_df &lt;-<span class="st"> </span>df[<span class="op">-</span>train.ID, ]</a>
<a class="sourceLine" id="cb83-7" data-line-number="7"></a>
<a class="sourceLine" id="cb83-8" data-line-number="8"><span class="co"># definimos como control una validación cruzada con 10 hojas, sin repeticiones</span></a>
<a class="sourceLine" id="cb83-9" data-line-number="9">fit_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb83-10" data-line-number="10"></a>
<a class="sourceLine" id="cb83-11" data-line-number="11"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb83-12" data-line-number="12">model_lda_def &lt;-<span class="st"> </span><span class="kw">train</span>(default <span class="op">~</span>.,</a>
<a class="sourceLine" id="cb83-13" data-line-number="13">                       <span class="dt">data =</span> train_df,</a>
<a class="sourceLine" id="cb83-14" data-line-number="14">                       <span class="dt">method =</span> <span class="st">&quot;lda&quot;</span>,</a>
<a class="sourceLine" id="cb83-15" data-line-number="15">                       <span class="dt">trControl =</span> fit_control)</a>
<a class="sourceLine" id="cb83-16" data-line-number="16">model_lda_def</a></code></pre></div>
<pre><code>## Linear Discriminant Analysis 
## 
## 8001 samples
##    2 predictor
##    2 classes: &#39;No&#39;, &#39;Yes&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 7200, 7200, 7201, 7202, 7201, 7202, ... 
## Resampling results:
## 
##   Accuracy  Kappa    
##   0.973379  0.3710518</code></pre>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb85-1" data-line-number="1">model_lda_def<span class="op">$</span>finalModel</a></code></pre></div>
<pre><code>## Call:
## lda(x, grouping = y)
## 
## Prior probabilities of groups:
##         No        Yes 
## 0.96662917 0.03337083 
## 
## Group means:
##       income   balance
## No  33513.73  805.9109
## Yes 32450.16 1753.3628
## 
## Coefficients of linear discriminants:
##                  LD1
## income  9.334558e-06
## balance 2.233976e-03</code></pre>
<p>La precisión durante el entrenamiento es de un <span class="math inline">\(\approx 97\%\)</span>. También vemos que las probabilidades a priori <span class="math inline">\(\pi_i, i = 1,2\)</span> de pertenecer a cada clase son aproximadamente <span class="math inline">\(97\%\)</span> y <span class="math inline">\(3\%\)</span> respectivamente, lo cual corresponde a la razón de fallo que se comenta al inicio. El resultado <code>Coefficients of linear discriminants</code> indica las constantes que se multiplican a cada elemento de la muestra <span class="math inline">\((\text{income}_i, \text{balance}_i)\)</span>, <span class="math inline">\(i = 1, \ldots, n_{\text{train}}\)</span>, para obtener su correspondiente valor de la <em>función discriminante lineal</em>:
<span class="math display">\[ \delta_k(x) = x^T \Sigma^{-1} \mu_k  - \dfrac{1}{2} \mu_k^T \Sigma^{-1} \mu_k+ log(\pi_k) \]</span>
Todo indica que la variable <code>balance</code> tiene un mayor peso en la discriminación. Como alternativa, podemos comprobarlo usando <code>varImp</code>:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb87-1" data-line-number="1"><span class="kw">varImp</span>(model_lda_def)</a></code></pre></div>
<pre><code>## ROC curve variable importance
## 
##         Importance
## balance        100
## income           0</code></pre>
<p>Veamos ahora qué tal es el ajuste en los datos test.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb89-1" data-line-number="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb89-2" data-line-number="2">prediction_lda_def &lt;-<span class="st"> </span><span class="kw">predict</span>(model_lda_def, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb89-3" data-line-number="3"><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   No  Yes
##        No  1927   54
##        Yes    6   12
##                                          
##                Accuracy : 0.97           
##                  95% CI : (0.9615, 0.977)
##     No Information Rate : 0.967          
##     P-Value [Acc &gt; NIR] : 0.2488         
##                                          
##                   Kappa : 0.2755         
##                                          
##  Mcnemar&#39;s Test P-Value : 1.298e-09      
##                                          
##             Sensitivity : 0.9969         
##             Specificity : 0.1818         
##          Pos Pred Value : 0.9727         
##          Neg Pred Value : 0.6667         
##              Prevalence : 0.9670         
##          Detection Rate : 0.9640         
##    Detection Prevalence : 0.9910         
##       Balanced Accuracy : 0.5894         
##                                          
##        &#39;Positive&#39; Class : No             
## </code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" data-line-number="1"><span class="co"># extraemos el Accuracy o Precisión</span></a>
<a class="sourceLine" id="cb91-2" data-line-number="2"><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a></code></pre></div>
<pre><code>## Accuracy 
## 0.969985</code></pre>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb93-1" data-line-number="1"><span class="co"># la tasa de error</span></a>
<a class="sourceLine" id="cb93-2" data-line-number="2">tasa.error.lda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">-</span><span class="kw">confusionMatrix</span>(prediction_lda_def, <span class="dt">reference =</span> test_df<span class="op">$</span>default)<span class="op">$</span>overall[<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb93-3" data-line-number="3"><span class="kw">names</span>(tasa.error.lda) &lt;-<span class="st"> &quot;Error LDA&quot;</span></a>
<a class="sourceLine" id="cb93-4" data-line-number="4">tasa.error.lda</a></code></pre></div>
<pre><code>##  Error LDA 
## 0.03001501</code></pre>
<p>Como estamos en un problema de clasificación en dos dimensiones (<span class="math inline">\(p = 2\)</span>), es posible representar la frontera de decisión del algoritmo, usando la función <code>decision_bound</code>. Debemos modificar los campos para que coincidan con las variables de <code>Default</code>:</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb95-1" data-line-number="1">decision_bound =<span class="st"> </span><span class="cf">function</span>(train_df_in, test_df_in, model_in){</a>
<a class="sourceLine" id="cb95-2" data-line-number="2">  <span class="co"># plot decision boundary  for df &lt;- Default[, c(&quot;income&quot;, &quot;balance&quot;, &quot;default&quot;)]</span></a>
<a class="sourceLine" id="cb95-3" data-line-number="3"></a>
<a class="sourceLine" id="cb95-4" data-line-number="4">  <span class="kw">require</span>(MASS)</a>
<a class="sourceLine" id="cb95-5" data-line-number="5">  <span class="kw">require</span>(caret)</a>
<a class="sourceLine" id="cb95-6" data-line-number="6">  <span class="kw">require</span>(ggplot2)</a>
<a class="sourceLine" id="cb95-7" data-line-number="7">  <span class="kw">require</span>(gridExtra)</a>
<a class="sourceLine" id="cb95-8" data-line-number="8"></a>
<a class="sourceLine" id="cb95-9" data-line-number="9">  <span class="co"># Paso 1: crear un grid de valores desde min a max de ambos predictores</span></a>
<a class="sourceLine" id="cb95-10" data-line-number="10">  pl =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>balance), <span class="kw">max</span>(train_df_in<span class="op">$</span>balance), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb95-11" data-line-number="11">  pw =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>income), <span class="kw">max</span>(train_df_in<span class="op">$</span>income), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb95-12" data-line-number="12"></a>
<a class="sourceLine" id="cb95-13" data-line-number="13">  lgrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">balance=</span>pl, <span class="dt">income=</span>pw)</a>
<a class="sourceLine" id="cb95-14" data-line-number="14"></a>
<a class="sourceLine" id="cb95-15" data-line-number="15">  <span class="co"># Paso 2: obtener las predicciones tanto para el grid como para el test</span></a>
<a class="sourceLine" id="cb95-16" data-line-number="16">  modelPredGrid &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata=</span>lgrid)</a>
<a class="sourceLine" id="cb95-17" data-line-number="17">  train_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> train_df_in)</a>
<a class="sourceLine" id="cb95-18" data-line-number="18">  test_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> test_df_in)</a>
<a class="sourceLine" id="cb95-19" data-line-number="19"></a>
<a class="sourceLine" id="cb95-20" data-line-number="20">  <span class="co"># Paso 3: ggplot con la funcion contour</span></a>
<a class="sourceLine" id="cb95-21" data-line-number="21">  gg1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-22" data-line-number="22"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-23" data-line-number="23"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-24" data-line-number="24"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Train&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-25" data-line-number="25"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>train_df_in,</a>
<a class="sourceLine" id="cb95-26" data-line-number="26">               <span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income,</a>
<a class="sourceLine" id="cb95-27" data-line-number="27">                   <span class="dt">colour=</span>default), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-28" data-line-number="28"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb95-29" data-line-number="29"></a>
<a class="sourceLine" id="cb95-30" data-line-number="30">  gg2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-31" data-line-number="31"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-32" data-line-number="32"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-33" data-line-number="33"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Test&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-34" data-line-number="34"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>test_df_in,</a>
<a class="sourceLine" id="cb95-35" data-line-number="35">               <span class="kw">aes</span>(<span class="dt">x=</span>balance, <span class="dt">y=</span>income,</a>
<a class="sourceLine" id="cb95-36" data-line-number="36">                   <span class="dt">colour=</span>default), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb95-37" data-line-number="37"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb95-38" data-line-number="38">  <span class="kw">grid.arrange</span>(gg1, gg2, <span class="dt">ncol=</span><span class="dv">1</span>, <span class="dt">nrow=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb95-39" data-line-number="39">}</a></code></pre></div>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" data-line-number="1"><span class="kw">decision_bound</span>(train_df, test_df, model_lda_def)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-43-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<p style="text-align: center;">
<a href="3-DA.html"><button class="btn btn-default">Previous</button></a>
<a href="3-2-QDA.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
