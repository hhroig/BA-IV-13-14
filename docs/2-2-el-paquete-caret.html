<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.2 El paquete caret | Introducción al Aprendizaje Supervisado" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento." />


<meta name="author" content="Harold A. Hernández-Roig (hahernan@est-econ.uc3m.es)" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Sesiones 13-15 IV Edición del Big Analytics: de la información al conocimiento.">

<title>2.2 El paquete caret | Introducción al Aprendizaje Supervisado</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#introducción"><span class="toc-section-number">1</span> Introducción</a></li>
<li class="has-sub"><a href="2-k-vecinos-más-próximos.html#k---vecinos-más-próximos"><span class="toc-section-number">2</span> K - Vecinos más Próximos</a><ul>
<li><a href="2-1-clasificación-con-el-paquete-class.html#clasificación-con-el-paquete-class"><span class="toc-section-number">2.1</span> Clasificación con el paquete <code>class</code></a></li>
<li class="has-sub"><a href="2-2-el-paquete-caret.html#el-paquete-caret"><span class="toc-section-number">2.2</span> El paquete <code>caret</code></a><ul>
<li><a href="2-2-el-paquete-caret.html#visualización"><span class="toc-section-number">2.2.1</span> Visualización</a></li>
<li><a href="2-2-el-paquete-caret.html#clasificación-con-knn"><span class="toc-section-number">2.2.2</span> Clasificación con KNN</a></li>
<li><a href="2-2-el-paquete-caret.html#importancia-de-las-variables"><span class="toc-section-number">2.2.3</span> Importancia de las variables</a></li>
</ul></li>
<li><a href="2-3-regresión.html#regresión"><span class="toc-section-number">2.3</span> Regresión</a></li>
<li><a href="2-4-weighted-knn.html#weighted-knn"><span class="toc-section-number">2.4</span> Weighted KNN</a></li>
</ul></li>
<li class="has-sub"><a href="3-DA.html#DA"><span class="toc-section-number">3</span> Análisis Discriminante</a><ul>
<li><a href="3-1-LDA.html#LDA"><span class="toc-section-number">3.1</span> Análisis Discriminante Lineal</a></li>
<li><a href="3-2-QDA.html#QDA"><span class="toc-section-number">3.2</span> Análisis Discriminante Cuadrático</a></li>
<li><a href="3-3-RDA.html#RDA"><span class="toc-section-number">3.3</span> Análisis Discriminante Regularizado</a></li>
</ul></li>
<li class="has-sub"><a href="4-compara.html#compara"><span class="toc-section-number">4</span> Comparación entre Modelos</a><ul>
<li><a href="4-1-comparando-según-accuracy.html#comparando-según-accuracy"><span class="toc-section-number">4.1</span> Comparando según <code>Accuracy</code></a></li>
<li class="has-sub"><a href="4-2-curva-roc.html#curva-roc"><span class="toc-section-number">4.2</span> Curva <em>ROC</em></a><ul>
<li><a href="4-2-curva-roc.html#análisis-en-la-muestra-test"><span class="toc-section-number">4.2.1</span> Análisis en la muestra test</a></li>
<li><a href="4-2-curva-roc.html#análisis-en-la-muestra-de-entrenamiento"><span class="toc-section-number">4.2.2</span> Análisis en la muestra de entrenamiento</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="5-wiscon.html#wiscon"><span class="toc-section-number">5</span> Wisconsin Breast-Cancer Data</a><ul>
<li><a href="5-1-comentarios-finales-reducción-de-la-dimensión.html#comentarios-finales-reducción-de-la-dimensión"><span class="toc-section-number">5.1</span> Comentarios finales: reducción de la dimensión</a></li>
</ul></li>
<li><a href="bibliografía.html#bibliografía">Bibliografía</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="el-paquete-caret" class="section level2">
<h2><span class="header-section-number">2.2</span> El paquete <code>caret</code></h2>
<p>El paquete <code>caret</code> (<em><strong>C</strong>lassification <strong>A</strong>nd <strong>RE</strong>gression <strong>T</strong>raining</em>) es uno de los más populares para entrenar modelos de <em>machine learning</em>. Contiene una interface uniforme para la mayoría de los algoritmos que se tratan en este curso y, en particular, los 3 que veremos en estas sesiones. Las ventajas del paquete son que permite hacer:</p>
<ul>
<li>partición de los datos</li>
<li>pre-procesado de los datos</li>
<li>selección de variables</li>
<li>ajuste del modelo usando remuestreo</li>
<li>estimación de la importancia/relevancia de las variables</li>
</ul>
<p>Más información disponible en <a href="http://topepo.github.io/caret/index.html">topepo.github.io/caret</a>.</p>
<div id="visualización" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Visualización</h3>
<p>Seguiremos con los datos <code>iris</code>. El paso inicial: análisis descriptivo y visualización de los datos podríamos obviarlo… pero a modo didáctico reproducimos el mismo análisis, esta vez usando la función <code>featurePlot</code> de <code>caret</code>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">library</span>(caret)</a></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">str</span>(iris)</a></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>Diagramas de dispersión:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">featurePlot</span>(<span class="dt">x =</span> iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], </a>
<a class="sourceLine" id="cb16-2" data-line-number="2">            <span class="dt">y =</span> iris<span class="op">$</span>Species, </a>
<a class="sourceLine" id="cb16-3" data-line-number="3">            <span class="dt">plot =</span> <span class="st">&quot;pairs&quot;</span>,</a>
<a class="sourceLine" id="cb16-4" data-line-number="4">            <span class="co">## Add a key at the top</span></a>
<a class="sourceLine" id="cb16-5" data-line-number="5">            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">3</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Densidades estimadas:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">featurePlot</span>(<span class="dt">x =</span> iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], </a>
<a class="sourceLine" id="cb17-2" data-line-number="2">            <span class="dt">y =</span> iris<span class="op">$</span>Species,</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">            <span class="dt">plot =</span> <span class="st">&quot;density&quot;</span>, </a>
<a class="sourceLine" id="cb17-4" data-line-number="4">            <span class="co">## Pass in options to xyplot() to </span></a>
<a class="sourceLine" id="cb17-5" data-line-number="5">            <span class="co">## make it prettier</span></a>
<a class="sourceLine" id="cb17-6" data-line-number="6">            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">relation=</span><span class="st">&quot;free&quot;</span>), </a>
<a class="sourceLine" id="cb17-7" data-line-number="7">                          <span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation=</span><span class="st">&quot;free&quot;</span>)), </a>
<a class="sourceLine" id="cb17-8" data-line-number="8">            <span class="dt">adjust =</span> <span class="fl">1.5</span>, </a>
<a class="sourceLine" id="cb17-9" data-line-number="9">            <span class="dt">pch =</span> <span class="st">&quot;|&quot;</span>, </a>
<a class="sourceLine" id="cb17-10" data-line-number="10">            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">1</span>), </a>
<a class="sourceLine" id="cb17-11" data-line-number="11">            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">3</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Diagramas de cajas:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">featurePlot</span>(<span class="dt">x =</span> iris[, <span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], </a>
<a class="sourceLine" id="cb18-2" data-line-number="2">            <span class="dt">y =</span> iris<span class="op">$</span>Species, </a>
<a class="sourceLine" id="cb18-3" data-line-number="3">            <span class="dt">plot =</span> <span class="st">&quot;box&quot;</span>, </a>
<a class="sourceLine" id="cb18-4" data-line-number="4">            <span class="co">## Pass in options to bwplot() </span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5">            <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">y =</span> <span class="kw">list</span>(<span class="dt">relation=</span><span class="st">&quot;free&quot;</span>),</a>
<a class="sourceLine" id="cb18-6" data-line-number="6">                          <span class="dt">x =</span> <span class="kw">list</span>(<span class="dt">rot =</span> <span class="dv">90</span>)),  </a>
<a class="sourceLine" id="cb18-7" data-line-number="7">            <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">4</span>,<span class="dv">1</span> ), </a>
<a class="sourceLine" id="cb18-8" data-line-number="8">            <span class="dt">auto.key =</span> <span class="kw">list</span>(<span class="dt">columns =</span> <span class="dv">2</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="clasificación-con-knn" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Clasificación con KNN</h3>
<p>Necesitamos extraer una muestra independiente (<em>test</em>) para probar el modelo, una vez ajustado. Ahora usaremos la función <code>createDataPartition</code>, que permite hacer la partición teniendo en cuenta la variable respuesta. Esto es esencial para mantener el balance de la muestra.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co"># creamos una partición test</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">df &lt;-<span class="st"> </span>iris</a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">123</span>)</a>
<a class="sourceLine" id="cb19-4" data-line-number="4">train.ID &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(df<span class="op">$</span>Species, <span class="dt">p =</span> <span class="fl">0.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a>
<a class="sourceLine" id="cb19-5" data-line-number="5"></a>
<a class="sourceLine" id="cb19-6" data-line-number="6">train_df &lt;-<span class="st"> </span>df[train.ID, ]</a>
<a class="sourceLine" id="cb19-7" data-line-number="7">test_df &lt;-<span class="st"> </span>df[<span class="op">-</span>train.ID, ]</a></code></pre></div>
<p>Para ajustar el modelo usaremos la función <code>train</code>, que permite:
* evaluar, usando remuestreo, el efecto de distintos parámetros en la precisión del modelo
* escoger el modelo óptimo, de acuerdo a los parámetros probados
* estimar la precisión del modelo, de acuerdo a diferentes medidas</p>
<p>Actualmente hay uno <span class="math inline">\(\approx 238\)</span> modelos disponibles. Nosotros empezaremos probando el <code>knn</code>, pero antes tenemos que especificar el método de remuestreo, usando la función <code>trainControl</code>. Con esta función, podemos fijar una validación cruzada <em>k-Fold</em> o <em>leave-one-out (LOOCV)</em>. También están disponibles las opciones <em>bootstrap</em> y <em>k-Fold repetitivo</em>.</p>
<p>En este ejemplo, hemos fijado un <em>k-Fold</em> con 10 hojas. Además, hacemos el escalado de las variables dentro del propio algoritmo, usando la opción <code>preProcess</code>. Finalmente, le decimos al algoritmo que intente 10 valores diferentes para escoger el número de vecinos óptimo, usando la opción <code>tuneLength</code></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="co"># primeros pasos con la validación cruzada...</span></a>
<a class="sourceLine" id="cb20-2" data-line-number="2">fit_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number =</span> <span class="dv">10</span>)  </a>
<a class="sourceLine" id="cb20-3" data-line-number="3"></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">model_knn_iris &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span>., </a>
<a class="sourceLine" id="cb20-5" data-line-number="5">                       <span class="dt">data =</span> train_df, </a>
<a class="sourceLine" id="cb20-6" data-line-number="6">                       <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, </a>
<a class="sourceLine" id="cb20-7" data-line-number="7">                       <span class="dt">trControl =</span> fit_control, </a>
<a class="sourceLine" id="cb20-8" data-line-number="8">                       <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </a>
<a class="sourceLine" id="cb20-9" data-line-number="9">                       <span class="dt">tuneLength =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb20-10" data-line-number="10">model_knn_iris</a></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa 
##    5  0.9666667  0.9500
##    7  0.9583333  0.9375
##    9  0.9750000  0.9625
##   11  0.9583333  0.9375
##   13  0.9583333  0.9375
##   15  0.9583333  0.9375
##   17  0.9583333  0.9375
##   19  0.9416667  0.9125
##   21  0.9500000  0.9250
##   23  0.9333333  0.9000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 9.</code></pre>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb22-1" data-line-number="1"><span class="kw">plot</span>(model_knn_iris)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-13-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Podemos ver en el resumen el número óptimo de vecinos (entre los valores probados) del modelo final. En el gráfico, vemos cómo varía el <em>accuracy</em> en función del número de vecinos. La tabla de confusión y medidas de precisión para los datos test:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2">prediction_knn_iris &lt;-<span class="st"> </span><span class="kw">predict</span>(model_knn_iris, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb23-3" data-line-number="3"><span class="kw">confusionMatrix</span>(prediction_knn_iris, <span class="dt">reference =</span> test_df<span class="op">$</span>Species)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         2
##   virginica       0          0         8
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9333          
##                  95% CI : (0.7793, 0.9918)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 8.747e-12       
##                                           
##                   Kappa : 0.9             
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.8000
## Specificity                 1.0000            0.9000           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              1.0000            1.0000           0.9091
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2667
## Detection Prevalence        0.3333            0.4000           0.2667
## Balanced Accuracy           1.0000            0.9500           0.9000</code></pre>
<p>Intentemos ahora fijar las cantidades de vecinos a probar. También cambiamos el método de remuestreo…</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="co"># definimos el grid:</span></a>
<a class="sourceLine" id="cb25-2" data-line-number="2">some_k &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">k =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">15</span>) </a>
<a class="sourceLine" id="cb25-3" data-line-number="3"></a>
<a class="sourceLine" id="cb25-4" data-line-number="4"><span class="co"># k-fold CV pero con repeticiones</span></a>
<a class="sourceLine" id="cb25-5" data-line-number="5">fit_control1 &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</a>
<a class="sourceLine" id="cb25-6" data-line-number="6">  <span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>, </a>
<a class="sourceLine" id="cb25-7" data-line-number="7">  <span class="dt">number =</span> <span class="dv">10</span>, <span class="co"># número de folds</span></a>
<a class="sourceLine" id="cb25-8" data-line-number="8">  <span class="dt">repeats =</span> <span class="dv">5</span> ) <span class="co"># repeticiones</span></a>
<a class="sourceLine" id="cb25-9" data-line-number="9"></a>
<a class="sourceLine" id="cb25-10" data-line-number="10"><span class="co"># bootstrap</span></a>
<a class="sourceLine" id="cb25-11" data-line-number="11">fit_control2 &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</a>
<a class="sourceLine" id="cb25-12" data-line-number="12">  <span class="dt">method =</span> <span class="st">&quot;boot&quot;</span>,  </a>
<a class="sourceLine" id="cb25-13" data-line-number="13">  <span class="dt">number =</span> <span class="dv">10</span>) <span class="co"># número de muestras bootstrap</span></a>
<a class="sourceLine" id="cb25-14" data-line-number="14"></a>
<a class="sourceLine" id="cb25-15" data-line-number="15"><span class="co"># LOOCV</span></a>
<a class="sourceLine" id="cb25-16" data-line-number="16">fit_control3 &lt;-<span class="st"> </span><span class="kw">trainControl</span>(</a>
<a class="sourceLine" id="cb25-17" data-line-number="17">  <span class="dt">method =</span> <span class="st">&quot;LOOCV&quot;</span>) </a>
<a class="sourceLine" id="cb25-18" data-line-number="18"></a>
<a class="sourceLine" id="cb25-19" data-line-number="19">model2_knn_iris &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span>., </a>
<a class="sourceLine" id="cb25-20" data-line-number="20">                        <span class="dt">data =</span> train_df, </a>
<a class="sourceLine" id="cb25-21" data-line-number="21">                        <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, </a>
<a class="sourceLine" id="cb25-22" data-line-number="22">                        <span class="dt">trControl =</span> fit_control2, </a>
<a class="sourceLine" id="cb25-23" data-line-number="23">                        <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </a>
<a class="sourceLine" id="cb25-24" data-line-number="24">                        <span class="dt">tuneGrid =</span> some_k)</a>
<a class="sourceLine" id="cb25-25" data-line-number="25">model2_knn_iris</a></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   4 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (4), scaled (4) 
## Resampling: Bootstrapped (10 reps) 
## Summary of sample sizes: 120, 120, 120, 120, 120, 120, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    1  0.9481717  0.9211545
##    2  0.9475159  0.9196833
##    3  0.9453882  0.9165257
##    4  0.9599231  0.9393154
##    5  0.9665503  0.9492382
##    6  0.9686637  0.9524826
##    7  0.9688968  0.9528083
##    8  0.9596084  0.9388259
##    9  0.9647549  0.9465745
##   10  0.9600366  0.9392605
##   11  0.9624756  0.9431153
##   12  0.9555270  0.9326274
##   13  0.9623479  0.9429620
##   14  0.9439143  0.9151811
##   15  0.9438559  0.9150458
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 7.</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="kw">plot</span>(model2_knn_iris)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb28-2" data-line-number="2">prediction_knn_iris2 &lt;-<span class="st"> </span><span class="kw">predict</span>(model2_knn_iris, <span class="dt">newdata =</span> test_df)</a>
<a class="sourceLine" id="cb28-3" data-line-number="3"><span class="kw">confusionMatrix</span>(prediction_knn_iris2, <span class="dt">reference =</span> test_df<span class="op">$</span>Species)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         2
##   virginica       0          0         8
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9333          
##                  95% CI : (0.7793, 0.9918)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 8.747e-12       
##                                           
##                   Kappa : 0.9             
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.8000
## Specificity                 1.0000            0.9000           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              1.0000            1.0000           0.9091
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2667
## Detection Prevalence        0.3333            0.4000           0.2667
## Balanced Accuracy           1.0000            0.9500           0.9000</code></pre>
</div>
<div id="importancia-de-las-variables" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Importancia de las variables</h3>
<p>Para KNN no tenemos un método que permita determinar la relevancia de cada predictor. Por ejemplo, en mínimos cuadrados, sí se puede conducir un test para determinar si cada coeficiente <span class="math inline">\(\beta_i\)</span> del modelo es significativamente distinto de cero. Aún así, <code>caret</code> incorpora la función <code>varImp</code> que da una medida de <em>importancia</em> de cada predictor del problema de clasificación o regresión.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1"><span class="kw">varImp</span>(model_knn_iris)</a></code></pre></div>
<pre><code>## ROC curve variable importance
## 
##   variables are sorted by maximum importance across the classes
##              setosa versicolor virginica
## Petal.Width  100.00     100.00     100.0
## Petal.Length 100.00     100.00     100.0
## Sepal.Length  90.80      72.07      90.8
## Sepal.Width   56.32      56.32       0.0</code></pre>
<p>Aunque esto no debe usarse como método de selección de variables, sí motiva el estudio del problema al disminuir la dimensión <span class="math inline">\(p = 4\)</span>. Por ejemplo, veamos la precisión del modelo al dejar solo <code>Petal.Length</code> y <code>Petal.Width</code>.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="co"># seleccionamos los predictores que queremos y la respuesta</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2">df_petal &lt;-<span class="st"> </span>iris[,<span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>, <span class="st">&quot;Species&quot;</span>)]</a>
<a class="sourceLine" id="cb32-3" data-line-number="3">train_df_petal &lt;-<span class="st"> </span>df_petal[train.ID, ]</a>
<a class="sourceLine" id="cb32-4" data-line-number="4">test_df_petal &lt;-<span class="st"> </span>df_petal[<span class="op">-</span>train.ID, ]</a>
<a class="sourceLine" id="cb32-5" data-line-number="5"></a>
<a class="sourceLine" id="cb32-6" data-line-number="6"><span class="co"># el modelo...</span></a>
<a class="sourceLine" id="cb32-7" data-line-number="7">fit_control &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&#39;cv&#39;</span>, <span class="dt">number =</span> <span class="dv">10</span>)  </a>
<a class="sourceLine" id="cb32-8" data-line-number="8"></a>
<a class="sourceLine" id="cb32-9" data-line-number="9">model_knn_petal &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span>., </a>
<a class="sourceLine" id="cb32-10" data-line-number="10">                        <span class="dt">data =</span> train_df_petal, </a>
<a class="sourceLine" id="cb32-11" data-line-number="11">                        <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, </a>
<a class="sourceLine" id="cb32-12" data-line-number="12">                        <span class="dt">trControl =</span> fit_control, </a>
<a class="sourceLine" id="cb32-13" data-line-number="13">                        <span class="dt">preProcess =</span> <span class="kw">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>),  </a>
<a class="sourceLine" id="cb32-14" data-line-number="14">                        <span class="dt">tuneLength =</span> <span class="dv">20</span>)</a>
<a class="sourceLine" id="cb32-15" data-line-number="15">model_knn_petal</a></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 120 samples
##   2 predictor
##   3 classes: &#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39; 
## 
## Pre-processing: centered (2), scaled (2) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 108, 108, 108, 108, 108, 108, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa 
##    5  0.9666667  0.9500
##    7  0.9666667  0.9500
##    9  0.9666667  0.9500
##   11  0.9666667  0.9500
##   13  0.9666667  0.9500
##   15  0.9666667  0.9500
##   17  0.9583333  0.9375
##   19  0.9666667  0.9500
##   21  0.9583333  0.9375
##   23  0.9666667  0.9500
##   25  0.9666667  0.9500
##   27  0.9666667  0.9500
##   29  0.9666667  0.9500
##   31  0.9666667  0.9500
##   33  0.9750000  0.9625
##   35  0.9833333  0.9750
##   37  0.9750000  0.9625
##   39  0.9833333  0.9750
##   41  0.9750000  0.9625
##   43  0.9666667  0.9500
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 39.</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1"><span class="kw">plot</span>(model_knn_petal)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb35-1" data-line-number="1"><span class="co"># hagamos las predicciones del conjunto de prueba</span></a>
<a class="sourceLine" id="cb35-2" data-line-number="2">prediction_knn_petal &lt;-<span class="st"> </span><span class="kw">predict</span>(model_knn_petal, <span class="dt">newdata =</span> test_df_petal)</a>
<a class="sourceLine" id="cb35-3" data-line-number="3"><span class="kw">confusionMatrix</span>(prediction_knn_petal, <span class="dt">reference =</span> test_df_petal<span class="op">$</span>Species)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         3
##   virginica       0          0         7
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9             
##                  95% CI : (0.7347, 0.9789)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 1.665e-10       
##                                           
##                   Kappa : 0.85            
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           0.7000
## Specificity                 1.0000            0.8500           1.0000
## Pos Pred Value              1.0000            0.7692           1.0000
## Neg Pred Value              1.0000            1.0000           0.8696
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.2333
## Detection Prevalence        0.3333            0.4333           0.2333
## Balanced Accuracy           1.0000            0.9250           0.8500</code></pre>
<p>Pero, ¿cómo visualizar las fronteras de decisión del método? Ahora que <span class="math inline">\(p = 2\)</span>, podemos representar esto en el plano usando la siguiente función:</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1">decision_bound =<span class="st"> </span><span class="cf">function</span>(train_df_in, test_df_in, model_in){</a>
<a class="sourceLine" id="cb37-2" data-line-number="2">  <span class="co"># plot decision boundary  for iris[,c(&quot;Petal.Length&quot;, &quot;Petal.Width&quot;, &quot;Species&quot;)]</span></a>
<a class="sourceLine" id="cb37-3" data-line-number="3"></a>
<a class="sourceLine" id="cb37-4" data-line-number="4">  <span class="kw">require</span>(MASS)</a>
<a class="sourceLine" id="cb37-5" data-line-number="5">  <span class="kw">require</span>(caret)</a>
<a class="sourceLine" id="cb37-6" data-line-number="6">  <span class="kw">require</span>(ggplot2)</a>
<a class="sourceLine" id="cb37-7" data-line-number="7">  <span class="kw">require</span>(gridExtra)</a>
<a class="sourceLine" id="cb37-8" data-line-number="8"></a>
<a class="sourceLine" id="cb37-9" data-line-number="9">  <span class="co"># Paso 1: crear un grid de valores desde min a max de ambos predictores</span></a>
<a class="sourceLine" id="cb37-10" data-line-number="10">  pl =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>Petal.Length), <span class="kw">max</span>(train_df_in<span class="op">$</span>Petal.Length), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb37-11" data-line-number="11">  pw =<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(train_df_in<span class="op">$</span>Petal.Width), <span class="kw">max</span>(train_df_in<span class="op">$</span>Petal.Width), <span class="dt">length.out =</span> <span class="dv">80</span>)</a>
<a class="sourceLine" id="cb37-12" data-line-number="12"></a>
<a class="sourceLine" id="cb37-13" data-line-number="13">  lgrid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">Petal.Length=</span>pl, <span class="dt">Petal.Width=</span>pw)</a>
<a class="sourceLine" id="cb37-14" data-line-number="14"></a>
<a class="sourceLine" id="cb37-15" data-line-number="15">  <span class="co"># Paso 2: obtener las predicciones tanto para el grid como para el test</span></a>
<a class="sourceLine" id="cb37-16" data-line-number="16">  modelPredGrid &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata=</span>lgrid)</a>
<a class="sourceLine" id="cb37-17" data-line-number="17">  train_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> train_df_in)</a>
<a class="sourceLine" id="cb37-18" data-line-number="18">  test_df_in<span class="op">$</span>Pred.Class &lt;-<span class="st"> </span><span class="kw">predict</span>(model_in, <span class="dt">newdata =</span> test_df_in)</a>
<a class="sourceLine" id="cb37-19" data-line-number="19"></a>
<a class="sourceLine" id="cb37-20" data-line-number="20">  <span class="co"># Paso 3: ggplot con la funcion contour</span></a>
<a class="sourceLine" id="cb37-21" data-line-number="21">  gg1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-22" data-line-number="22"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-23" data-line-number="23"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-24" data-line-number="24"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Train&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-25" data-line-number="25"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>train_df_in,</a>
<a class="sourceLine" id="cb37-26" data-line-number="26">               <span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width,</a>
<a class="sourceLine" id="cb37-27" data-line-number="27">                   <span class="dt">colour=</span>Species), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-28" data-line-number="28"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb37-29" data-line-number="29"></a>
<a class="sourceLine" id="cb37-30" data-line-number="30">  gg2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span>lgrid) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-31" data-line-number="31"><span class="st">    </span><span class="kw">stat_contour</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width, <span class="dt">z=</span><span class="kw">as.numeric</span>(modelPredGrid)), <span class="dt">bins=</span><span class="dv">2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-32" data-line-number="32"><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width, <span class="dt">colour=</span>modelPredGrid), <span class="dt">alpha=</span><span class="fl">0.1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-33" data-line-number="33"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">colour =</span> <span class="st">&quot;Clases&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Test&quot;</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-34" data-line-number="34"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">data=</span>test_df_in,</a>
<a class="sourceLine" id="cb37-35" data-line-number="35">               <span class="kw">aes</span>(<span class="dt">x=</span>Petal.Length, <span class="dt">y=</span>Petal.Width,</a>
<a class="sourceLine" id="cb37-36" data-line-number="36">                   <span class="dt">colour=</span>Species), <span class="dt">size=</span><span class="dv">5</span>, <span class="dt">shape=</span><span class="dv">1</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb37-37" data-line-number="37"><span class="st">    </span><span class="kw">theme_light</span>()</a>
<a class="sourceLine" id="cb37-38" data-line-number="38">  <span class="kw">grid.arrange</span>(gg1, gg2, <span class="dt">ncol=</span><span class="dv">1</span>, <span class="dt">nrow=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb37-39" data-line-number="39">}</a></code></pre></div>
<p>Así que aplicando esto a nuestros datos de entrenamiento (o los del test) obtenemos las fronteras de decisión:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1"><span class="co"># fronteras de decisión, usando la nueva función</span></a>
<a class="sourceLine" id="cb38-2" data-line-number="2"><span class="kw">decision_bound</span>(train_df_petal, test_df_petal, model_knn_petal)</a></code></pre></div>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## Loading required package: gridExtra</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-21-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<p style="text-align: center;">
<a href="2-1-clasificación-con-el-paquete-class.html"><button class="btn btn-default">Previous</button></a>
<a href="2-3-regresión.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
